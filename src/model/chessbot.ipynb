{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports that are necessary for the engine to function correclty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sqlalchemy import create_engine, Column, Integer, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is connecting to the database of elite chess games, making it possible to fetch data later on in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\736078126.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ChessGame(Base):\n",
    "    __tablename__ = 'games'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pgn = Column(Text)\n",
    "\n",
    "engine = create_engine('sqlite:///../chess_games.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening book is a very useful tool when creating a Chess Engine because it makes it possible for the model to take part of large theory knowledge. Below are some functions to use an opening book in pgn format. Also searching in the opening book for matching moves in order to make it more dynamic. When choosing move, it might select a random move out of the matching openings in order to make the games less deterministic and more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's next move: e5\n"
     ]
    }
   ],
   "source": [
    "def load_openings_from_pgn(pgn_file):\n",
    "    openings = []\n",
    "    with open(pgn_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            moves = []\n",
    "            for move in game.mainline_moves():\n",
    "                moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "\n",
    "            openings.append(moves)\n",
    "    return openings\n",
    "\n",
    "#Function to find matching openings based on played moves\n",
    "def find_matching_openings(played_moves, openings):\n",
    "    \"\"\"\n",
    "    Finding opening works by checking if the played moves match the start of any opening in the opening book.\n",
    "    This is because a chosen opening can be diverged from at any point by the opponent.\n",
    "    This makes the bot more dynamic in the opening phase.\n",
    "    \"\"\"\n",
    "    matching_openings = []\n",
    "    for opening in openings:\n",
    "        if played_moves == opening[:len(played_moves)]:\n",
    "            matching_openings.append(opening)\n",
    "    return matching_openings\n",
    "\n",
    "#Function to choose the next move from matching openings\n",
    "def select_next_move(played_moves, matching_openings, rand = True):\n",
    "    if not matching_openings:\n",
    "        return None  # No matching opening found, time for engine\n",
    "\n",
    "    \n",
    "    if rand:\n",
    "        chosen_opening = random.choice(matching_openings)\n",
    "\n",
    "        if len(chosen_opening) > len(played_moves):\n",
    "            next_move = chosen_opening[len(played_moves)]\n",
    "            return next_move\n",
    "    else:\n",
    "        for opening in matching_openings:\n",
    "            if len(opening) > len(played_moves):\n",
    "                next_move = opening[len(played_moves)]\n",
    "                return next_move\n",
    "    return None  # No more moves in the opening book, time for engine\n",
    "\n",
    "#Load the openings\n",
    "openings = load_openings_from_pgn(\"eco.pgn\")\n",
    "\n",
    "#Example usage\n",
    "played_moves = [\"e4\"]  \n",
    "matching_openings = find_matching_openings(played_moves, openings)\n",
    "next_move = select_next_move(played_moves, matching_openings)\n",
    "\n",
    "if next_move:\n",
    "    print(f\"Bot's next move: {next_move}\")\n",
    "else:\n",
    "    print(\"No matching opening found, calculate the move using engine logic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture is a CNN-Transformer. The CNN part is used to extract features from the board state and the Transformer part is used to make predictions based on the features extracted by the CNN. This is a powerful architecture when dealing with chess because it can learn to recognize patterns in the board state and make predictions based on those patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, padding=1) # 13 channels for the 12 piece types and an extra channel for the color the bot is playing\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "#Positional encoding for the transformer in order to give the model information about the position of the pieces\n",
    "#Uses the sine and cosine functions to encode the position of the board in a unique way\n",
    "#Experimental, might be overkill. Saw somewhere it could be useful for the transformer, but not sure if it is properly implemented here\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, d_model, 2).float()\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding = self.encoding.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:x.size(0), :].to(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old model that used 12 channels in the input convolutional layer instead of 13, because I was stupid and did not clarify for the engine which side it was playing. Code is still here for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNetOld(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNetOld, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop and some functions for training the model is coded below. Using cross entropy loss and Adam optimizer, the model becomes pretty good at predicting the elite player's move in a given board state. Moves are also skipped in the beginning of the games to not unfairly punish the model for not predicting the first moves correctly, since most opening moves are interchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_input(board, is_white):\n",
    "    board_planes = np.zeros((8, 8, 13), dtype=np.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    return board_planes\n",
    "\n",
    "#Encode the move TODO: Make it possible to encode promotion moves. ATM it only encodes the move from and to square and is unable to promote.\n",
    "def move_to_output(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_35920\\396689620.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/new_model_1275.pth')) #Load the model from the previous training session\n",
      "Processing Batch 1:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2d4\n",
      "f8e7\n",
      "d1c2\n",
      "e8g8\n",
      "b1d2\n",
      "b7b6\n",
      "e2e4\n",
      "c8b7\n",
      "e4e5\n",
      "f6e8\n",
      "c4d5\n",
      "e6d5\n",
      "f1e1\n",
      "e8c7\n",
      "d2f1\n",
      "c7e6\n",
      "f1e3\n",
      "c6c5\n",
      "e3f5\n",
      "a8c8\n",
      "c2d1\n",
      "f8e8\n",
      "c1e3\n",
      "e7f8\n",
      "g2h3\n",
      "f7f6\n",
      "e5f6\n",
      "d8f6\n",
      "d1d2\n",
      "h7h6\n",
      "f3e5\n",
      "d7e5\n",
      "d4e5\n",
      "f6f7\n",
      "e3h6\n",
      "g7h6\n",
      "f5h6\n",
      "f8h6\n",
      "d2h6\n",
      "d5d4\n",
      "f2f4\n",
      "e6g7\n",
      "e5e6\n",
      "f7c7\n",
      "e1e2\n",
      "g1f3\n",
      "b8d7\n",
      "f1d3\n",
      "e6e5\n",
      "d4e5\n",
      "d7e5\n",
      "f3e5\n",
      "d6e5\n",
      "d2f3\n",
      "e5b2\n",
      "a1b1\n",
      "b2c3\n",
      "f3d2\n",
      "c3e5\n",
      "g3e5\n",
      "e7e5\n",
      "e1g1\n",
      "e8g8\n",
      "c2c4\n",
      "c7c6\n",
      "c4d5\n",
      "f6d5\n",
      "d2f3\n",
      "e5f6\n",
      "d1c2\n",
      "g7g6\n",
      "d3c4\n",
      "d5b6\n",
      "c4d3\n",
      "f8d8\n",
      "f1c1\n",
      "f6e7\n",
      "f3d4\n",
      "b6d5\n",
      "c2b2\n",
      "c6c5\n",
      "d4e2\n",
      "b7b6\n",
      "e2c3\n",
      "d5c3\n",
      "b2c3\n",
      "d8d3\n",
      "c3d3\n",
      "c8f5\n",
      "e3e4\n",
      "e7e4\n",
      "d3e4\n",
      "f5e4\n",
      "b1b2\n",
      "a8d8\n",
      "f2f3\n",
      "e4c6\n",
      "g1f2\n",
      "d8d3\n",
      "c1e1\n",
      "g8f8\n",
      "e1e5\n",
      "c6d5\n",
      "a2a4\n",
      "f7f6\n",
      "e5e3\n",
      "d3d4\n",
      "a4a5\n",
      "b6a5\n",
      "b2b5\n",
      "d4d2\n",
      "f2g3\n",
      "c5c4\n",
      "b5a5\n",
      "d5f7\n",
      "a5a7\n",
      "f6f5\n",
      "a7c7\n",
      "g6g5\n",
      "e3e1\n",
      "h7h5\n",
      "f3f4\n",
      "h5h4\n",
      "g3h3\n",
      "f7d5\n",
      "c7c8\n",
      "f8g7\n",
      "f4g5\n",
      "d5g2\n",
      "h3h4\n",
      "d2d4\n",
      "h4g3\n",
      "g2e4\n",
      "g5g6\n",
      "g7g6\n",
      "c8c5\n",
      "g6g5\n",
      "e1e3\n",
      "d4d3\n",
      "g3f2\n",
      "d3d2\n",
      "f2e1\n",
      "d2d3\n",
      "e1f2\n",
      "g5f4\n",
      "e3d3\n",
      "c4d3\n",
      "c5c8\n",
      "f4g4\n",
      "c8g8\n",
      "g4f4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 111\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(games), game_batch_size):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m#if offset // batch_size + 1 <63:\u001b[39;00m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;66;03m#break\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     game_batch \u001b[38;5;241m=\u001b[39m [game\u001b[38;5;241m.\u001b[39mpgn \u001b[38;5;28;01mfor\u001b[39;00m game \u001b[38;5;129;01min\u001b[39;00m games[i:i \u001b[38;5;241m+\u001b[39m game_batch_size]]\n\u001b[1;32m--> 111\u001b[0m     loss, accuracy, moves \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_moves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m moves\n\u001b[0;32m    113\u001b[0m     total_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy \u001b[38;5;241m*\u001b[39m moves\n",
      "Cell \u001b[1;32mIn[69], line 48\u001b[0m, in \u001b[0;36mtrain_on_batch\u001b[1;34m(games, model, optimizer, criterion, device, skip_moves)\u001b[0m\n\u001b[0;32m     46\u001b[0m is_white \u001b[38;5;241m=\u001b[39m board\u001b[38;5;241m.\u001b[39mturn \u001b[38;5;241m==\u001b[39m chess\u001b[38;5;241m.\u001b[39mWHITE\n\u001b[0;32m     47\u001b[0m board_input \u001b[38;5;241m=\u001b[39m board_to_input(board, is_white)\n\u001b[1;32m---> 48\u001b[0m board_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m actual_output \u001b[38;5;241m=\u001b[39m move_to_output(move)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(move)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training step with move skipping and batching\n",
    "def train_on_batch(games, model, optimizer, criterion, device, skip_moves=10):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "\n",
    "    for game_str in games:\n",
    "        pgn_io = io.StringIO(game_str)\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        board = game.board()\n",
    "        move_count = 0\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            #A static number of moves are skipped to avoid overfitting to the opening book\n",
    "            #More sophisticated methods can be used to skip exact amount of book moves, but it is too inefficient for my machine\n",
    "            if move_count < skip_moves:\n",
    "                board.push(move)\n",
    "                move_count += 1\n",
    "                continue\n",
    "\n",
    "            #Prepare the input and output\n",
    "            is_white = board.turn == chess.WHITE\n",
    "            board_input = board_to_input(board, is_white)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(move)\n",
    "            print(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            #Update the board with the actual move\n",
    "            board.push(move)\n",
    "\n",
    "    if all_board_inputs:\n",
    "        #Stack all inputs and targets\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del batch_inputs, batch_targets, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "#Training loop\n",
    "batch_size = 1024\n",
    "game_batch_size = 16 \n",
    "offset = 0\n",
    "step = 0\n",
    "j = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/new_model_1275.pth')) #Load the model from the previous training session\n",
    "#model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    games = session.query(ChessGame).offset(offset).limit(batch_size).all()\n",
    "    if not games:\n",
    "        break\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(games) // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        \n",
    "        for i in range(0, len(games), game_batch_size):\n",
    "            #if offset // batch_size + 1 <63:\n",
    "                #break\n",
    "            game_batch = [game.pgn for game in games[i:i + game_batch_size]]\n",
    "            loss, accuracy, moves = train_on_batch(game_batch, model, optimizer, criterion, device, skip_moves=10)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "\n",
    "            del game_batch, loss, accuracy, moves\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    j += 1\n",
    "    if j % 25 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'new_model_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    model_save_path = os.path.join('savedModels', f'new_model_current.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n",
    "    \n",
    "#Close the session and TensorBoard writer\n",
    "#Still have not tried TensorBoard, might not work\n",
    "session.close()\n",
    "model_save_path = os.path.join('savedModels', f'new_model_final.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#1291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 PuzzleId                                                FEN  \\\n",
      "0           0    00008  r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - ...   \n",
      "1           1    0000D  5rk1/1p3ppp/pq3b2/8/8/1P1Q1N2/P4PPP/3R2K1 w - ...   \n",
      "2           2    000Vc             8/8/4k1p1/2KpP2p/5PP1/8/8/8 w - - 0 53   \n",
      "3           3    000Zo  4r3/1k6/pp3r2/1b2P2p/3R1p2/P1R2P2/1P4PP/6K1 w ...   \n",
      "4           4    000mr  5r1k/5rp1/p7/1b2B2p/1P1P1Pq1/2R1Q3/P3p1P1/2R3K...   \n",
      "\n",
      "                           Moves  Rating  RatingDeviation  Popularity  \\\n",
      "0  f2g3 e6e7 b2b1 b3c1 b1c1 h6c1    1736               78          95   \n",
      "1            d3d6 f8d8 d6d8 f6d8    1513               74          96   \n",
      "2  g4h5 g6h5 f4f5 e6e5 f5f6 e5f6    1495              155         100   \n",
      "3            e5f6 e8e1 g1f2 e1f1    1652              149         100   \n",
      "4            e3g3 f7f4 e5f4 f8f4    1478              279         100   \n",
      "\n",
      "   NbPlays                                 Themes  \\\n",
      "0     3012  crushing hangingPiece long middlegame   \n",
      "1    16164                advantage endgame short   \n",
      "2       14      crushing endgame long pawnEndgame   \n",
      "3       23             endgame mate mateIn2 short   \n",
      "4       10              crushing middlegame short   \n",
      "\n",
      "                                 GameUrl  \n",
      "0  https://lichess.org/787zsVup/black#48  \n",
      "1        https://lichess.org/F8M8OS71#53  \n",
      "2       https://lichess.org/l6AejDMO#105  \n",
      "3        https://lichess.org/n8Ff742v#69  \n",
      "4        https://lichess.org/8sVpuwso#81  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2568096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzles_df = pd.read_csv('../../Datasets/lichess_puzzle_transformed.csv')\n",
    "\n",
    "print(puzzles_df.head())\n",
    "len(puzzles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\1359270542.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/new_model_current.pth')) #Load the model from the previous training session\n",
      "Processing Batch 1:   0%|          | 0/64 [00:00<?, ?it/s]C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\1359270542.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  fen = row[2]\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\1359270542.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  move_sequence = row[3].split()\n",
      "Processing Batch 1: 100%|██████████| 64/64 [00:10<00:00,  5.98it/s, Loss=1.33, Accuracy=0.591]\n",
      "Processing Batch 2: 100%|██████████| 64/64 [00:09<00:00,  6.47it/s, Loss=1.28, Accuracy=0.61] \n",
      "Processing Batch 3: 100%|██████████| 64/64 [00:09<00:00,  6.60it/s, Loss=1.29, Accuracy=0.607]\n",
      "Processing Batch 4: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, Loss=1.25, Accuracy=0.609]\n",
      "Processing Batch 5: 100%|██████████| 64/64 [00:11<00:00,  5.70it/s, Loss=1.26, Accuracy=0.613]\n",
      "Processing Batch 6: 100%|██████████| 64/64 [00:10<00:00,  6.06it/s, Loss=1.26, Accuracy=0.614]\n",
      "Processing Batch 7: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, Loss=1.25, Accuracy=0.614]\n",
      "Processing Batch 8: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, Loss=1.26, Accuracy=0.61] \n",
      "Processing Batch 9: 100%|██████████| 64/64 [00:10<00:00,  6.21it/s, Loss=1.24, Accuracy=0.617]\n",
      "Processing Batch 10: 100%|██████████| 64/64 [00:09<00:00,  6.42it/s, Loss=1.23, Accuracy=0.621]\n",
      "Processing Batch 11: 100%|██████████| 64/64 [00:09<00:00,  6.93it/s, Loss=1.25, Accuracy=0.614]\n",
      "Processing Batch 12: 100%|██████████| 64/64 [00:09<00:00,  6.96it/s, Loss=1.25, Accuracy=0.613]\n",
      "Processing Batch 13: 100%|██████████| 64/64 [00:09<00:00,  6.88it/s, Loss=1.24, Accuracy=0.614]\n",
      "Processing Batch 14: 100%|██████████| 64/64 [00:09<00:00,  6.80it/s, Loss=1.26, Accuracy=0.61] \n",
      "Processing Batch 15: 100%|██████████| 64/64 [00:09<00:00,  6.90it/s, Loss=1.24, Accuracy=0.618]\n",
      "Processing Batch 16: 100%|██████████| 64/64 [00:09<00:00,  6.88it/s, Loss=1.24, Accuracy=0.621]\n",
      "Processing Batch 17: 100%|██████████| 64/64 [00:09<00:00,  6.91it/s, Loss=1.23, Accuracy=0.618]\n",
      "Processing Batch 18: 100%|██████████| 64/64 [00:09<00:00,  6.83it/s, Loss=1.24, Accuracy=0.618]\n",
      "Processing Batch 19: 100%|██████████| 64/64 [00:09<00:00,  6.87it/s, Loss=1.22, Accuracy=0.624]\n",
      "Processing Batch 20: 100%|██████████| 64/64 [00:09<00:00,  6.95it/s, Loss=1.23, Accuracy=0.619]\n",
      "Processing Batch 21: 100%|██████████| 64/64 [00:09<00:00,  6.95it/s, Loss=1.23, Accuracy=0.621]\n",
      "Processing Batch 22: 100%|██████████| 64/64 [00:09<00:00,  6.98it/s, Loss=1.23, Accuracy=0.618]\n",
      "Processing Batch 23: 100%|██████████| 64/64 [00:09<00:00,  6.68it/s, Loss=1.25, Accuracy=0.617]\n",
      "Processing Batch 24: 100%|██████████| 64/64 [00:09<00:00,  6.68it/s, Loss=1.24, Accuracy=0.614]\n",
      "Processing Batch 25: 100%|██████████| 64/64 [00:09<00:00,  6.73it/s, Loss=1.21, Accuracy=0.624]\n",
      "Processing Batch 26: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, Loss=1.23, Accuracy=0.626]\n",
      "Processing Batch 27: 100%|██████████| 64/64 [00:09<00:00,  6.87it/s, Loss=1.22, Accuracy=0.623]\n",
      "Processing Batch 28: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, Loss=1.22, Accuracy=0.62] \n",
      "Processing Batch 29: 100%|██████████| 64/64 [00:09<00:00,  6.82it/s, Loss=1.23, Accuracy=0.616]\n",
      "Processing Batch 30: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, Loss=1.23, Accuracy=0.62] \n",
      "Processing Batch 31: 100%|██████████| 64/64 [00:09<00:00,  6.65it/s, Loss=1.21, Accuracy=0.627]\n",
      "Processing Batch 32: 100%|██████████| 64/64 [00:09<00:00,  6.55it/s, Loss=1.24, Accuracy=0.618]\n",
      "Processing Batch 33: 100%|██████████| 64/64 [00:09<00:00,  6.50it/s, Loss=1.22, Accuracy=0.619]\n",
      "Processing Batch 34: 100%|██████████| 64/64 [00:09<00:00,  6.77it/s, Loss=1.21, Accuracy=0.623]\n",
      "Processing Batch 35: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, Loss=1.22, Accuracy=0.626]\n",
      "Processing Batch 36: 100%|██████████| 64/64 [00:09<00:00,  6.75it/s, Loss=1.22, Accuracy=0.616]\n",
      "Processing Batch 37: 100%|██████████| 64/64 [00:09<00:00,  6.76it/s, Loss=1.21, Accuracy=0.627]\n",
      "Processing Batch 38: 100%|██████████| 64/64 [00:09<00:00,  6.80it/s, Loss=1.21, Accuracy=0.625]\n",
      "Processing Batch 39: 100%|██████████| 64/64 [00:09<00:00,  6.78it/s, Loss=1.19, Accuracy=0.627]\n",
      "Processing Batch 40: 100%|██████████| 64/64 [00:09<00:00,  6.77it/s, Loss=1.2, Accuracy=0.626] \n",
      "Processing Batch 41: 100%|██████████| 64/64 [00:10<00:00,  6.13it/s, Loss=1.21, Accuracy=0.624]\n",
      "Processing Batch 42: 100%|██████████| 64/64 [00:10<00:00,  6.17it/s, Loss=1.21, Accuracy=0.63] \n",
      "Processing Batch 43: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, Loss=1.21, Accuracy=0.628]\n",
      "Processing Batch 44: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, Loss=1.21, Accuracy=0.623]\n",
      "Processing Batch 45: 100%|██████████| 64/64 [00:09<00:00,  6.73it/s, Loss=1.21, Accuracy=0.63] \n",
      "Processing Batch 46: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, Loss=1.24, Accuracy=0.616]\n",
      "Processing Batch 47: 100%|██████████| 64/64 [00:09<00:00,  6.72it/s, Loss=1.19, Accuracy=0.63] \n",
      "Processing Batch 48: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, Loss=1.2, Accuracy=0.631] \n",
      "Processing Batch 49: 100%|██████████| 64/64 [00:09<00:00,  6.60it/s, Loss=1.22, Accuracy=0.625]\n",
      "Processing Batch 50: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, Loss=1.21, Accuracy=0.625]\n",
      "Processing Batch 51: 100%|██████████| 64/64 [00:09<00:00,  6.68it/s, Loss=1.2, Accuracy=0.631] \n",
      "Processing Batch 52: 100%|██████████| 64/64 [00:09<00:00,  6.76it/s, Loss=1.21, Accuracy=0.63] \n",
      "Processing Batch 53: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, Loss=1.2, Accuracy=0.63]  \n",
      "Processing Batch 54: 100%|██████████| 64/64 [00:09<00:00,  6.80it/s, Loss=1.22, Accuracy=0.623]\n",
      "Processing Batch 55: 100%|██████████| 64/64 [00:10<00:00,  6.31it/s, Loss=1.21, Accuracy=0.627]\n",
      "Processing Batch 56: 100%|██████████| 64/64 [00:11<00:00,  5.66it/s, Loss=1.19, Accuracy=0.635]\n",
      "Processing Batch 57: 100%|██████████| 64/64 [00:10<00:00,  6.32it/s, Loss=1.19, Accuracy=0.631]\n",
      "Processing Batch 58: 100%|██████████| 64/64 [00:10<00:00,  6.36it/s, Loss=1.22, Accuracy=0.626]\n",
      "Processing Batch 59: 100%|██████████| 64/64 [00:09<00:00,  6.48it/s, Loss=1.21, Accuracy=0.626]\n",
      "Processing Batch 60: 100%|██████████| 64/64 [00:09<00:00,  6.59it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 61: 100%|██████████| 64/64 [00:09<00:00,  6.81it/s, Loss=1.2, Accuracy=0.63]  \n",
      "Processing Batch 62: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, Loss=1.19, Accuracy=0.634]\n",
      "Processing Batch 63: 100%|██████████| 64/64 [00:09<00:00,  6.81it/s, Loss=1.19, Accuracy=0.63] \n",
      "Processing Batch 64: 100%|██████████| 64/64 [00:09<00:00,  6.84it/s, Loss=1.19, Accuracy=0.631]\n",
      "Processing Batch 65: 100%|██████████| 64/64 [00:09<00:00,  6.82it/s, Loss=1.22, Accuracy=0.621]\n",
      "Processing Batch 66: 100%|██████████| 64/64 [00:09<00:00,  6.89it/s, Loss=1.22, Accuracy=0.626]\n",
      "Processing Batch 67: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, Loss=1.19, Accuracy=0.632]\n",
      "Processing Batch 68: 100%|██████████| 64/64 [00:09<00:00,  6.88it/s, Loss=1.21, Accuracy=0.63] \n",
      "Processing Batch 69: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, Loss=1.21, Accuracy=0.628]\n",
      "Processing Batch 70: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 71: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, Loss=1.22, Accuracy=0.625]\n",
      "Processing Batch 72: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, Loss=1.19, Accuracy=0.635]\n",
      "Processing Batch 73: 100%|██████████| 64/64 [00:09<00:00,  6.41it/s, Loss=1.19, Accuracy=0.634]\n",
      "Processing Batch 74: 100%|██████████| 64/64 [00:09<00:00,  6.62it/s, Loss=1.18, Accuracy=0.635]\n",
      "Processing Batch 75: 100%|██████████| 64/64 [00:09<00:00,  6.77it/s, Loss=1.18, Accuracy=0.637]\n",
      "Processing Batch 76: 100%|██████████| 64/64 [00:09<00:00,  6.71it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 77: 100%|██████████| 64/64 [00:09<00:00,  6.65it/s, Loss=1.2, Accuracy=0.632] \n",
      "Processing Batch 78: 100%|██████████| 64/64 [00:09<00:00,  6.68it/s, Loss=1.19, Accuracy=0.63] \n",
      "Processing Batch 79: 100%|██████████| 64/64 [00:09<00:00,  6.54it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 80: 100%|██████████| 64/64 [00:09<00:00,  6.52it/s, Loss=1.19, Accuracy=0.632]\n",
      "Processing Batch 81: 100%|██████████| 64/64 [00:09<00:00,  6.44it/s, Loss=1.18, Accuracy=0.638]\n",
      "Processing Batch 82: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, Loss=1.2, Accuracy=0.629] \n",
      "Processing Batch 83: 100%|██████████| 64/64 [00:12<00:00,  5.31it/s, Loss=1.21, Accuracy=0.627]\n",
      "Processing Batch 84: 100%|██████████| 64/64 [00:10<00:00,  5.85it/s, Loss=1.19, Accuracy=0.627]\n",
      "Processing Batch 85: 100%|██████████| 64/64 [00:11<00:00,  5.81it/s, Loss=1.2, Accuracy=0.626] \n",
      "Processing Batch 86: 100%|██████████| 64/64 [00:10<00:00,  5.99it/s, Loss=1.19, Accuracy=0.635]\n",
      "Processing Batch 87: 100%|██████████| 64/64 [00:11<00:00,  5.68it/s, Loss=1.2, Accuracy=0.632] \n",
      "Processing Batch 88: 100%|██████████| 64/64 [00:11<00:00,  5.78it/s, Loss=1.19, Accuracy=0.629]\n",
      "Processing Batch 89: 100%|██████████| 64/64 [00:10<00:00,  6.20it/s, Loss=1.19, Accuracy=0.63] \n",
      "Processing Batch 90: 100%|██████████| 64/64 [00:10<00:00,  5.85it/s, Loss=1.19, Accuracy=0.634]\n",
      "Processing Batch 91: 100%|██████████| 64/64 [00:11<00:00,  5.58it/s, Loss=1.18, Accuracy=0.63] \n",
      "Processing Batch 92: 100%|██████████| 64/64 [00:11<00:00,  5.75it/s, Loss=1.18, Accuracy=0.638]\n",
      "Processing Batch 93: 100%|██████████| 64/64 [00:10<00:00,  6.38it/s, Loss=1.18, Accuracy=0.641]\n",
      "Processing Batch 94: 100%|██████████| 64/64 [00:10<00:00,  6.23it/s, Loss=1.18, Accuracy=0.639]\n",
      "Processing Batch 95: 100%|██████████| 64/64 [00:09<00:00,  6.55it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 96: 100%|██████████| 64/64 [00:09<00:00,  6.49it/s, Loss=1.19, Accuracy=0.635]\n",
      "Processing Batch 97: 100%|██████████| 64/64 [00:09<00:00,  6.61it/s, Loss=1.18, Accuracy=0.636]\n",
      "Processing Batch 98: 100%|██████████| 64/64 [00:09<00:00,  6.51it/s, Loss=1.2, Accuracy=0.628] \n",
      "Processing Batch 99: 100%|██████████| 64/64 [00:09<00:00,  6.55it/s, Loss=1.19, Accuracy=0.633]\n",
      "Processing Batch 100:   9%|▉         | 6/64 [00:01<00:10,  5.45it/s, Loss=1.14, Accuracy=0.646]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m puzzle_batch \u001b[38;5;241m=\u001b[39m puzzles_df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39moffset:i\u001b[38;5;241m+\u001b[39moffset\u001b[38;5;241m+\u001b[39mgame_batch_size]\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m#print(puzzle_batch.head())\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m loss, accuracy, moves \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_puzzle_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpuzzle_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m moves\n\u001b[0;32m     93\u001b[0m total_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy \u001b[38;5;241m*\u001b[39m moves\n",
      "Cell \u001b[1;32mIn[9], line 52\u001b[0m, in \u001b[0;36mtrain_on_puzzle_batch\u001b[1;34m(puzzle_batch, model, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     51\u001b[0m predicted_moves \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted_moves\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_targets)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m batch_inputs, batch_targets, output\n\u001b[0;32m     56\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_on_puzzle_batch(puzzle_batch, model, optimizer, criterion, device):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "    # Loop through the dataframe in batches\n",
    "        \n",
    "\n",
    "    for _, row in puzzle_batch.iterrows():\n",
    "        # Extract FEN and move sequence\n",
    "        fen = row[2]\n",
    "        #print(fen)\n",
    "        move_sequence = row[3].split()\n",
    "        #print(move_sequence)\n",
    "        # Initialize the board from the starting FEN\n",
    "        board = chess.Board(fen)\n",
    "\n",
    "        # Process the sequence of moves one by one\n",
    "        for move in move_sequence:\n",
    "            # Convert the board to the input tensor\n",
    "\n",
    "            is_white = board.turn == chess.WHITE\n",
    "            board_input = board_to_input(board, is_white)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(chess.Move.from_uci(move))\n",
    "            #print(actual_output)\n",
    "            #print(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            # Apply the correct move to the board, so the next input is the real next position\n",
    "            board.push(chess.Move.from_uci(move))\n",
    "    \n",
    "    if all_board_inputs:\n",
    "        # Stack inputs and targets into tensors\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_moves = torch.argmax(output, dim=1)\n",
    "        accuracy = (predicted_moves == batch_targets).sum().item() / len(batch_targets)\n",
    "\n",
    "\n",
    "        del batch_inputs, batch_targets, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "batch_size = 4096\n",
    "game_batch_size = 64\n",
    "offset = 0\n",
    "step = 0\n",
    "j = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/puzzle_trained_current.pth')) #Load the model from the previous training session\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    #puzzles_df = pd.read_csv('../../Datasets/lichess_puzzle_transformed.csv')\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    \n",
    "    with tqdm(total=batch_size // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        \n",
    "        for i in range(0, batch_size, game_batch_size):\n",
    "            if offset // batch_size + 1 <100:\n",
    "                break\n",
    "            # Get the batch of puzzles\n",
    "            #i += offset\n",
    "            puzzle_batch = puzzles_df.iloc[i+offset:i+offset+game_batch_size]\n",
    "            #print(puzzle_batch.head())\n",
    "            loss, accuracy, moves = train_on_puzzle_batch(puzzle_batch, model, optimizer, criterion, device)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "\n",
    "            del loss, accuracy, moves, puzzle_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            if i > offset + batch_size:\n",
    "                break\n",
    "    \n",
    "    j += 1\n",
    "    if j % 25 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'puzzle_trained_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    model_save_path = os.path.join('savedModels', f'puzzle_trained_current.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RL part is not implemented yet, but below is an attempt to create one. I believe the idea and strategy can be correct if properly implemented, but as of right now it is not working as well as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RL PART ######\n",
    "\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
    "\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "# Function to select a move given the current board position. Not currently used in the training loop whilst trying to fix some stuff\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0) \n",
    "\n",
    "    \n",
    "    logits = model(state) \n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    # Sample from moves based on the distribution of probabilities.\n",
    "    # In the early stages of training, the bot will explore many moves that it does not particularly prefer, \n",
    "    # but as the training progresses, the bot will start to get better, the distribution of probabilities of moves will more greatly favor the better moves, \n",
    "    # leading to less exploration.\n",
    "    move_idx = m.sample() \n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "# Function to simulate a batch of games of self-play\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = [board_to_input(boards[i]) for i in active_indices]\n",
    "        states = torch.cat(states).to(device)\n",
    "\n",
    "        \n",
    "        logits = model(states) \n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                print(\"All legal probabilities are zero\")\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx) \n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                #Greatly reward the bot for checkmating the opponent\n",
    "                rewards[i].append(5)\n",
    "                break\n",
    "\n",
    "            # If too many moves, break\n",
    "            if len(rewards[i]) > 200:\n",
    "                boards[i].push(chess.Move.null())\n",
    "                # Penalize the bot for taking too many moves\n",
    "                rewards[i][-1] -= 0.5\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i]\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "        \n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01 # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1 \n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1  \n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5  \n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5  \n",
    "\n",
    "    del states, logits, probabilities\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return log_probs, rewards, checkmate_count\n",
    "\n",
    "\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "# Function to assign value to pieces TODO: fix right values since these are maybe not good\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 0.1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 0.3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 0.5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 0.9\n",
    "    return 0\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, gamma=0.99):\n",
    "    policy_loss = 0\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns, dtype=torch.float32, requires_grad=False).to(device) # requires_grad=False since having problems with torch.no_grad during self-play. Trying to fix it\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            policy_loss += -log_prob * R\n",
    "\n",
    "    return policy_loss\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=4, accumulation_steps=4):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
    "    total_checkmates = 0\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        episode_loss = 0\n",
    "\n",
    "        for _ in range(accumulation_steps):\n",
    "            log_probs_batch, rewards_batch, checkmate_count = play_batch_games(model, batch_size)\n",
    "            \n",
    "            # Ensure autocast is used only during forward pass\n",
    "            with autocast(device_type=\"cuda\"):  # Enable mixed precision during policy update\n",
    "                policy_loss = update_policy_batch(log_probs_batch, rewards_batch, optimizer)\n",
    "\n",
    "                # Accumulate the loss\n",
    "                episode_loss += policy_loss / accumulation_steps\n",
    "\n",
    "        # Check that episode_loss requires gradients\n",
    "       # assert episode_loss.requires_grad, \"episode_loss does not require gradients.\"\n",
    "\n",
    "        # Backward pass with scaled gradients after accumulation\n",
    "        scaler.scale(episode_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_checkmates += checkmate_count  #Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates / (episode + 1) * batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=16, accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attempt at RL below, skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming your ChessNet model is defined elsewhere\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth'))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Functions to convert board states and moves\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input.to(device)\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 9\n",
    "    return 0\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "def center_control(board):\n",
    "    central_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "    control_score = 0\n",
    "\n",
    "    for square in central_squares:\n",
    "        attackers = board.attackers(chess.WHITE, square)\n",
    "        defenders = board.attackers(chess.BLACK, square)\n",
    "\n",
    "        if len(attackers) > len(defenders):\n",
    "            control_score += 0.1\n",
    "        elif len(attackers) < len(defenders):\n",
    "            control_score -= 0.1\n",
    "\n",
    "    return control_score\n",
    "\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(state)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    move_idx = m.sample()\n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "def dynamic_gamma(move_count):\n",
    "    if move_count < 20:\n",
    "        return 0.95  # Early game\n",
    "    elif move_count < 40:\n",
    "        return 0.98  # Mid game\n",
    "    else:\n",
    "        return 0.99  # End game\n",
    "\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    move_count = 0\n",
    "\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = torch.cat([board_to_input(boards[i]) for i in active_indices])\n",
    "\n",
    "        logits = model(states)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx)\n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            current_control_score = center_control(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i] + current_control_score\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "            move_count += 1\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "\n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01  # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5\n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5\n",
    "\n",
    "    return log_probs, rewards, checkmate_count, move_count\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count):\n",
    "    optimizer.zero_grad()\n",
    "    gamma = dynamic_gamma(move_count)\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns).to(device)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            loss = -log_prob * R\n",
    "            scaler.scale(loss).backward(retain_graph=True)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4):\n",
    "    model.train()\n",
    "    total_checkmates = 0\n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        log_probs_batch, rewards_batch, checkmate_count, move_count = play_batch_games(model, batch_size)\n",
    "        update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count)\n",
    "\n",
    "        total_checkmates += checkmate_count  # Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates/(episode+1)*batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Start training\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can play against the engine. It is painstakingly infuriating to play, since there is no real UI and you have to input the moves in uci format. Will fix integration with the chess game and UI soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChessNet()\n",
    "model.load_state_dict(torch.load('savedModels/new_model_current.pth'))\n",
    "model.eval()\n",
    "\n",
    "board = chess.Board()\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 13), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    \n",
    "    is_white = board.turn == chess.WHITE\n",
    "    board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    \n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "    return board_input\n",
    "\n",
    "def predict_move(model, board):\n",
    "    board_input = board_to_input(board)\n",
    "    with torch.no_grad():\n",
    "        output = model(board_input)\n",
    "    \n",
    "    move_scores = output.squeeze().sort(descending=True)\n",
    "    move_indices = move_scores.indices.tolist()\n",
    "    \n",
    "    for move_index in move_indices:\n",
    "        from_square = move_index // 64\n",
    "        to_square = move_index % 64\n",
    "        move = chess.Move(from_square, to_square)\n",
    "        #if pawn and last character is 1 or eight, add 'q' to the move\n",
    "        #Hopefully this works, always promotes to queen\n",
    "        if board.piece_at(from_square).piece_type == 1 and (str(move)[-1] == '1' or str(move)[-1] == '8'):\n",
    "            move = chess.Move(from_square, to_square, promotion=5) \n",
    "        print(move, move_scores.values[move_index].item())\n",
    "        \n",
    "        if move in board.legal_moves:\n",
    "            return move\n",
    "    \n",
    "    # If no valid moves are found (which shouldn't happen), return None\n",
    "    return None\n",
    "\n",
    "played_moves = []\n",
    "opening_phase = True\n",
    "player_white = False\n",
    "first_move_done = False\n",
    "while not board.is_game_over():\n",
    "    display(board)  \n",
    "    \n",
    "\n",
    "    if player_white or first_move_done:\n",
    "        user_move = input(\"Your move: \")\n",
    "        try:\n",
    "            move = chess.Move.from_uci(user_move)\n",
    "            if move in board.legal_moves:\n",
    "                played_moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "            else:\n",
    "                print(\"Invalid move. Try again.\")\n",
    "                continue\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Use UCI format (e.g., e2e4).\")\n",
    "            continue\n",
    "\n",
    "    if board.is_game_over():\n",
    "        break\n",
    "    #Get the bots move\n",
    "    if opening_phase:\n",
    "        matching_openings = find_matching_openings(played_moves, openings)\n",
    "        next_move = select_next_move(played_moves, matching_openings)\n",
    "    if opening_phase and next_move:\n",
    "        print(\"a\")\n",
    "        played_moves.append(next_move)\n",
    "        move = board.parse_san(next_move)\n",
    "        board.push(move)\n",
    "    else:\n",
    "        bot_move = predict_move(model, board)\n",
    "        opening_phase = False\n",
    "        if bot_move:\n",
    "            board.push(bot_move)\n",
    "        else:\n",
    "            print(\"Bot could not find a valid move.\")\n",
    "            break\n",
    "    first_move_done = True\n",
    "\n",
    "print(\"Game over!\")\n",
    "print(f\"Result: {board.result()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having two different models meet each other for x amount of games to see which is the best. Also saving the games in pgn format for later analysis is games.pgn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\1337475681.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/puzzle_trained_current.pth'))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_32908\\1337475681.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  modelOld.load_state_dict(torch.load('savedModels/new_model_current.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "0\n",
      "e2e4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "1\n",
      "d2d4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "2\n",
      "d2d4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "3\n",
      "d2d4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "4\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "5\n",
      "e2e4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "6\n",
      "d2d4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "7\n",
      "e2e4\n",
      "c4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "8\n",
      "c2c4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "9\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "10\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "11\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "12\n",
      "e2e4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "13\n",
      "d2d4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "14\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "15\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "16\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "17\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "18\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "19\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "20\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "21\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "22\n",
      "e2e4\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "23\n",
      "g1f3\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "24\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "25\n",
      "e2e4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "26\n",
      "d2d4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "27\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "28\n",
      "e2e4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "29\n",
      "d2d4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "30\n",
      "e2e4\n",
      "e4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e4\n",
      "31\n",
      "e2e4\n",
      "0\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "1\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "2\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "3\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "4\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "7\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "8\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "9\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "10\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "11\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "12\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "13\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "14\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "15\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "16\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "17\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "18\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "19\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "20\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "21\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "22\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "23\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "24\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "25\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "26\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "27\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "28\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "29\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "30\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "31\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "e2e4\n",
      "b\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "c5\n",
      "c7c5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "c5\n",
      "c7c5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . P . . . . .\n",
      ". . . . . . . .\n",
      "P P . P P P P P\n",
      "R N B Q K B N R\n",
      "c5\n",
      "c7c5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "c6\n",
      "c7c6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "c5\n",
      "c7c5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e6\n",
      "e7e6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "0\n",
      "g1f3\n",
      "c4\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "1\n",
      "c2c4\n",
      "c4\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "2\n",
      "c2c4\n",
      "c4\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "3\n",
      "c2c4\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "4\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "5\n",
      "g1f3\n",
      "c4\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "6\n",
      "c2c4\n",
      "b4\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "b4\n",
      "7\n",
      "b2b4\n",
      "Nc3\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . P . . . . .\n",
      ". . . . . . . .\n",
      "P P . P P P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "8\n",
      "b1c3\n",
      "Nc3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "9\n",
      "b1c3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "10\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "11\n",
      "g1f3\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . p . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "12\n",
      "d2d4\n",
      "c4\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "13\n",
      "c2c4\n",
      "Bc4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Bc4\n",
      "14\n",
      "f1c4\n",
      "f4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f4\n",
      "15\n",
      "f2f4\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "16\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "17\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "18\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "19\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "20\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "21\n",
      "g1f3\n",
      "f4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f4\n",
      "22\n",
      "f2f4\n",
      "c4\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "c4\n",
      "23\n",
      "c2c4\n",
      "b4\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "b4\n",
      "24\n",
      "b2b4\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "25\n",
      "d2d4\n",
      "c4\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "26\n",
      "c2c4\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "27\n",
      "g1f3\n",
      "f4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f4\n",
      "28\n",
      "f2f4\n",
      "c4\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c4\n",
      "29\n",
      "c2c4\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "30\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "31\n",
      "g1f3\n",
      "0\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "1\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "2\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "3\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "5\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "6\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "7\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "b2b4\n",
      "8\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . P . . . . .\n",
      ". . . . . . . .\n",
      "P P . P P P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "9\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "10\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "11\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "12\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . p . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "13\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "14\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f1c4\n",
      "15\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f2f4\n",
      "16\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "17\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "18\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "19\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "20\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "21\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "22\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f2f4\n",
      "23\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "c2c4\n",
      "24\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "b2b4\n",
      "25\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "d2d4\n",
      "26\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "27\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "28\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "f2f4\n",
      "29\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . P P P P\n",
      "R N B Q K B N R\n",
      "c2c4\n",
      "30\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "31\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "b\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g6\n",
      "g7g6\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g6\n",
      "g7g6\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "e5\n",
      "e7e5\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "e6\n",
      "e7e6\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "e6\n",
      "e7e6\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". P . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "cxb4\n",
      "c5b4\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". . P . . . . .\n",
      ". . N . . . . .\n",
      "P P . P P P P P\n",
      "R . B Q K B N R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . N . . . . .\n",
      "P P P P . P P P\n",
      "R . B Q K B N R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . p . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g6\n",
      "g7g6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . B . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K . N R\n",
      "Bc5\n",
      "f8c5\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "exf4\n",
      "e5f4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "Qf6\n",
      "d8f6\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . P . . . . .\n",
      ". . . . . N . .\n",
      "P P . P P P P P\n",
      "R N B Q K B . R\n",
      "d4\n",
      "d5d4\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . p . . . . .\n",
      ". P . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "cxb4\n",
      "c5b4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . p . . .\n",
      ". . . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "c6\n",
      "c7c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "Bc5\n",
      "f8c5\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g6\n",
      "g7g6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc6\n",
      "b8c6\n",
      "Bb5\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bb5\n",
      "0\n",
      "f1b5\n",
      "Nc3\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "1\n",
      "b1c3\n",
      "Nc3\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "2\n",
      "b1c3\n",
      "dxe5\n",
      "r n b q k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "dxe5\n",
      "3\n",
      "d4e5\n",
      "Nc3\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nc3\n",
      "4\n",
      "b1c3\n",
      "d4\n",
      "r n b q k b n r\n",
      "p p . p . p p p\n",
      ". . . . p . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d4\n",
      "5\n",
      "d2d4\n",
      "g3\n",
      "r n b q k b . r\n",
      "p p p p . p p p\n",
      ". . . . p n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g3\n",
      "6\n",
      "g2g3\n",
      "a3\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". p . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "a3\n",
      "7\n",
      "a2a3\n",
      "g3\n",
      "r . b q k b n r\n",
      "p p . p p p p p\n",
      ". . n . . . . .\n",
      ". . p . . . . .\n",
      ". . P . . . . .\n",
      ". . N . . . . .\n",
      "P P . P P P P P\n",
      "R . B Q K B N R\n",
      "g3\n",
      "8\n",
      "g2g3\n",
      "f4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . N . . . . .\n",
      "P P P P . P P P\n",
      "R . B Q K B N R\n",
      "f4\n",
      "9\n",
      "f2f4\n",
      "Bc4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bc4\n",
      "10\n",
      "f1c4\n",
      "d4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d4\n",
      "11\n",
      "d2d4\n",
      "exd5\n",
      "r n b q k b n r\n",
      "p p . . p p p p\n",
      ". . p . . . . .\n",
      ". . . p . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "exd5\n",
      "12\n",
      "e4d5\n",
      "Nc3\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "13\n",
      "b1c3\n",
      "b4\n",
      "r n b q k . n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . b . p . . .\n",
      ". . B . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K . N R\n",
      "b4\n",
      "14\n",
      "b2b4\n",
      "Bc4\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P p . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "Bc4\n",
      "15\n",
      "f1c4\n",
      "d4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d4\n",
      "16\n",
      "d2d4\n",
      "Bc4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bc4\n",
      "17\n",
      "f1c4\n",
      "Bc4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bc4\n",
      "18\n",
      "f1c4\n",
      "Bc4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bc4\n",
      "19\n",
      "f1c4\n",
      "Bb5\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bb5\n",
      "20\n",
      "f1b5\n",
      "Bb5\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bb5\n",
      "21\n",
      "f1b5\n",
      "Nf3\n",
      "r n b . k b n r\n",
      "p p p p . p p p\n",
      ". . . . . q . .\n",
      ". . . . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "22\n",
      "g1f3\n",
      "None\n",
      "a3\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". p . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "a3\n",
      "24\n",
      "a2a3\n",
      "Nc3\n",
      "r n b q k b n r\n",
      "p p p . . p p p\n",
      ". . . . p . . .\n",
      ". . . p . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "Nc3\n",
      "25\n",
      "b1c3\n",
      "Nf3\n",
      "r n b q k b n r\n",
      "p p . . p p p p\n",
      ". . p . . . . .\n",
      ". . . p . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "26\n",
      "g1f3\n",
      "Bb5\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bb5\n",
      "27\n",
      "f1b5\n",
      "Nf3\n",
      "r n b q k . n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . b . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "28\n",
      "g1f3\n",
      "Nf3\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "Nf3\n",
      "29\n",
      "g1f3\n",
      "Nxe5\n",
      "r n b q k b . r\n",
      "p p p p . p p p\n",
      ". . . . . n . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Nxe5\n",
      "30\n",
      "f3e5\n",
      "Bb5\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "Bb5\n",
      "31\n",
      "f1b5\n",
      "0\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1b5\n",
      "1\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "2\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "3\n",
      "r n b q k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "d4e5\n",
      "4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "b1c3\n",
      "5\n",
      "r n b q k b n r\n",
      "p p . p . p p p\n",
      ". . . . p . . .\n",
      ". . p . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d2d4\n",
      "6\n",
      "r n b q k b . r\n",
      "p p p p . p p p\n",
      ". . . . p n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g2g3\n",
      "7\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". p . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "a2a3\n",
      "8\n",
      "r . b q k b n r\n",
      "p p . p p p p p\n",
      ". . n . . . . .\n",
      ". . p . . . . .\n",
      ". . P . . . . .\n",
      ". . N . . . . .\n",
      "P P . P P P P P\n",
      "R . B Q K B N R\n",
      "g2g3\n",
      "9\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . N . . . . .\n",
      "P P P P . P P P\n",
      "R . B Q K B N R\n",
      "f2f4\n",
      "10\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1c4\n",
      "11\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d2d4\n",
      "12\n",
      "r n b q k b n r\n",
      "p p . . p p p p\n",
      ". . p . . . . .\n",
      ". . . p . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "e4d5\n",
      "13\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "14\n",
      "r n b q k . n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . b . p . . .\n",
      ". . B . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K . N R\n",
      "b2b4\n",
      "15\n",
      "r n b q k b n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P p . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "f1c4\n",
      "16\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "d2d4\n",
      "17\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1c4\n",
      "18\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1c4\n",
      "19\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1c4\n",
      "20\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1b5\n",
      "21\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1b5\n",
      "22\n",
      "r n b . k b n r\n",
      "p p p p . p p p\n",
      ". . . . . q . .\n",
      ". . . . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "23\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . P p . . . .\n",
      ". . . . . N . .\n",
      "P P . P P P P P\n",
      "R N B Q K B . R\n",
      "e2e3\n",
      "24\n",
      "r n b q k b n r\n",
      "p p . p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". p . . P . . .\n",
      ". . . . . . . .\n",
      "P . P P . P P P\n",
      "R N B Q K B N R\n",
      "a2a3\n",
      "25\n",
      "r n b q k b n r\n",
      "p p p . . p p p\n",
      ". . . . p . . .\n",
      ". . . p . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "b1c3\n",
      "26\n",
      "r n b q k b n r\n",
      "p p . . p p p p\n",
      ". . p . . . . .\n",
      ". . . p . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "27\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1b5\n",
      "28\n",
      "r n b q k . n r\n",
      "p p p p . p p p\n",
      ". . . . . . . .\n",
      ". . b . p . . .\n",
      ". . . . P P . .\n",
      ". . . . . . . .\n",
      "P P P P . . P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "29\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "g1f3\n",
      "30\n",
      "r n b q k b . r\n",
      "p p p p . p p p\n",
      ". . . . . n . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f3e5\n",
      "31\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K B . R\n",
      "f1b5\n",
      "b\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". B . . p . . .\n",
      ". . . . P . . .\n",
      ". . . . . N . .\n",
      "P P P P . P P P\n",
      "R N B Q K . . R\n",
      "a6\n",
      "a7a6\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . N . . . . .\n",
      "P P . . P P P P\n",
      "R . B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b . r\n",
      "p p p p p p . p\n",
      ". . . . . n p .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . N . . . . .\n",
      "P P . . P P P P\n",
      "R . B Q K B N R\n",
      "d5\n",
      "d7d5\n",
      "r n b q k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p P . . .\n",
      ". . P . . . . .\n",
      ". . . . . . . .\n",
      "P P . . P P P P\n",
      "R N B Q K B N R\n",
      "d4\n",
      "d5d4\n",
      "r . b q k b n r\n",
      "p p p p . p p p\n",
      ". . n . . . . .\n",
      ". . . . p . . .\n",
      ". . . . P . . .\n",
      ". . N . . N . .\n",
      "P P P P . P P P\n",
      "R . B Q K B . R\n",
      "Nf6\n",
      "g8f6\n",
      "r n b q k b n r\n",
      "p p . p . p p p\n",
      ". . . . p . . .\n",
      ". . p . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K B . R\n",
      "cxd4\n",
      "c5d4\n",
      "r n b q k b . r\n",
      "p p p p . p p p\n",
      ". . . . p n . .\n",
      ". . . . . . . .\n",
      ". . P P . . . .\n",
      ". . . . . . P .\n",
      "P P . . P P . P\n",
      "R N B Q K B N R\n",
      "d5\n",
      "d7d5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 13, 3, 3], expected input[1, 12, 8, 8] to have 13 channels, but got 12 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 155\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# First 500 games: new model as White, old model as Black\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m500\u001b[39m, batch_size):\n\u001b[1;32m--> 155\u001b[0m     batch_results \u001b[38;5;241m=\u001b[39m \u001b[43mplay_games_in_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelOld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m batch_results:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1-0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[13], line 123\u001b[0m, in \u001b[0;36mplay_games_in_batch\u001b[1;34m(model_white, model_black, batch_size, new_num_layers, pgn_filename)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(move)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;66;03m#print(i)\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m         black_moves\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpredict_moves_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_black\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mboards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_num_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     black_moves\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m, in \u001b[0;36mpredict_moves_batch\u001b[1;34m(model, boards, param)\u001b[0m\n\u001b[0;32m     35\u001b[0m board_inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([board_to_input(board, param) \u001b[38;5;28;01mfor\u001b[39;00m board \u001b[38;5;129;01min\u001b[39;00m boards])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m moves \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, board \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, boards):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m, in \u001b[0;36mChessNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)  \n\u001b[0;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 13, 3, 3], expected input[1, 12, 8, 8] to have 13 channels, but got 12 channels instead"
     ]
    }
   ],
   "source": [
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/puzzle_trained_current.pth'))\n",
    "model.eval()\n",
    "\n",
    "modelOld = ChessNet().to(device)\n",
    "modelOld.load_state_dict(torch.load('savedModels/new_model_current.pth'))\n",
    "modelOld.eval()\n",
    "\n",
    "def save_game_to_pgn(board, result, filename=\"games.pgn\"):\n",
    "    game = chess.pgn.Game.from_board(board)\n",
    "    game.headers[\"Result\"] = result\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(str(game) + \"\\n\\n\")\n",
    "\n",
    "def board_to_input(board, param):\n",
    "    board_planes = torch.zeros((8, 8, param), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    \n",
    "    if param == 13:\n",
    "        is_white = board.turn == chess.WHITE\n",
    "        board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    \n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "\n",
    "    return board_input\n",
    "\n",
    "def predict_moves_batch(model, boards, param):\n",
    "    board_inputs = torch.cat([board_to_input(board, param) for board in boards]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(board_inputs)\n",
    "    \n",
    "    moves = []\n",
    "    for output, board in zip(outputs, boards):\n",
    "        move_scores = output.squeeze().sort(descending=True)\n",
    "        move_indices = move_scores.indices.tolist()\n",
    "\n",
    "        for move_index in move_indices:\n",
    "            from_square = move_index // 64\n",
    "            to_square = move_index % 64\n",
    "            move = chess.Move(from_square, to_square)\n",
    "            if board.piece_at(from_square) and board.piece_at(from_square).piece_type == chess.PAWN and (str(move)[-1] == '1' or str(move)[-1] == '8'):\n",
    "                move = chess.Move(from_square, to_square, promotion=chess.QUEEN)\n",
    "\n",
    "            if move in board.legal_moves:\n",
    "                moves.append(move)\n",
    "                break\n",
    "        else:\n",
    "            moves.append(None)  # No valid move found\n",
    "    return moves\n",
    "\n",
    "def play_games_in_batch(model_white, model_black, batch_size, new_num_layers, pgn_filename=\"games.pgn\"):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    active = [True] * batch_size\n",
    "    results = []\n",
    "    played_moves_list = [[] for _ in range(batch_size)]  # Track the played moves for each game\n",
    "\n",
    "    while any(active):\n",
    "        # White's moves\n",
    "        white_moves = []\n",
    "        for i in range(batch_size):\n",
    "            if active[i]:\n",
    "                matching_openings = find_matching_openings(played_moves_list[i], openings)\n",
    "                next_move = select_next_move(played_moves_list[i], matching_openings)\n",
    "                print(next_move)\n",
    "                if next_move:\n",
    "                    print(boards[i])\n",
    "                    print(next_move)\n",
    "                    print(i)\n",
    "                \n",
    "                    move = boards[i].parse_san(next_move)\n",
    "                    print(move)\n",
    "                    \n",
    "                    white_moves.append(move)\n",
    "                else:\n",
    "                    white_moves.append(predict_moves_batch(model_white, [boards[i]], 13)[0])\n",
    "            else:\n",
    "                white_moves.append(None)\n",
    "\n",
    "        for i, move in enumerate(white_moves):\n",
    "            if active[i]:\n",
    "                if move:\n",
    "                    print(i)\n",
    "                    print(boards[i])\n",
    "                    print(move)\n",
    "                    \n",
    "                    played_moves_list[i].append(boards[i].san(move))\n",
    "                    boards[i].push(move) \n",
    "                \n",
    "                if boards[i].is_checkmate(): \n",
    "                    result = \"1-0\" \n",
    "                    active[i] = False\n",
    "                    results.append(result)\n",
    "                    save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "                elif boards[i].is_game_over():\n",
    "                    result = \"1/2-1/2\"\n",
    "                    print(result)\n",
    "                    active[i] = False\n",
    "                    results.append(result)\n",
    "                    save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "        print(\"b\")\n",
    "        # Black's moves\n",
    "        if any(active):\n",
    "            black_moves = []\n",
    "            for i in range(batch_size):\n",
    "                if active[i]:\n",
    "                    matching_openings = find_matching_openings(played_moves_list[i], openings)\n",
    "                    next_move = select_next_move(played_moves_list[i], matching_openings)\n",
    "                    if next_move:\n",
    "                        print(boards[i])\n",
    "                        print(next_move)\n",
    "                        move = boards[i].parse_san(next_move)\n",
    "                        black_moves.append(move)\n",
    "                        print(move)\n",
    "                    else:\n",
    "                        #print(i)\n",
    "                        black_moves.append(predict_moves_batch(model_black, [boards[i]], 13)[0])\n",
    "                else:\n",
    "                    black_moves.append(None)\n",
    "\n",
    "            for i, move in enumerate(black_moves):\n",
    "                if active[i]:\n",
    "                    if move:\n",
    "                        played_moves_list[i].append(boards[i].san(move))\n",
    "                        boards[i].push(move)\n",
    "                        \n",
    "                    if boards[i].is_checkmate(): \n",
    "                        result = \"0-1\" \n",
    "                        active[i] = False\n",
    "                        results.append(result)\n",
    "                        save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "\n",
    "                    elif boards[i].is_game_over():\n",
    "                        result = \"1/2-1/2\"\n",
    "                        print(result)\n",
    "                        active[i] = False\n",
    "                        results.append(result)\n",
    "                        save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the batch of games\n",
    "total_games = 1000\n",
    "batch_size = 32  # Adjust batch size based on your GPU capacity\n",
    "results = {'new_model_wins': 0, 'old_model_wins': 0, 'draws': 0}\n",
    "\n",
    "# First 500 games: new model as White, old model as Black\n",
    "for i in range(0, 500, batch_size):\n",
    "    batch_results = play_games_in_batch(model, modelOld, min(batch_size, 500 - i), True)\n",
    "    \n",
    "    for result in batch_results:\n",
    "        if result == '1-0':\n",
    "            results['new_model_wins'] += 1\n",
    "        elif result == '0-1':\n",
    "            results['old_model_wins'] += 1\n",
    "        else:\n",
    "            results['draws'] += 1\n",
    "\n",
    "# Second 500 games: old model as White, new model as Black\n",
    "for i in range(0, 500, batch_size):\n",
    "    batch_results = play_games_in_batch(modelOld, model, min(batch_size, 500 - i), True)\n",
    "    \n",
    "    for result in batch_results:\n",
    "        if result == '1-0':\n",
    "            results['old_model_wins'] += 1\n",
    "        elif result == '0-1':\n",
    "            results['new_model_wins'] += 1\n",
    "        else:\n",
    "            results['draws'] += 1\n",
    "\n",
    "print(\"Simulation complete!\")\n",
    "print(f\"New Model Wins: {results['new_model_wins']}\")\n",
    "print(f\"Old Model Wins: {results['old_model_wins']}\")\n",
    "print(f\"Draws: {results['draws']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
