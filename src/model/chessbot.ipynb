{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports that are necessary for the engine to function correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sqlalchemy import create_engine, Column, Integer, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is connecting to the database of elite chess games, making it possible to fetch data later on in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ChessGame(Base):\n",
    "    __tablename__ = 'games'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pgn = Column(Text)\n",
    "\n",
    "engine = create_engine('sqlite:///../chess_games.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening book is a very useful tool when creating a Chess Engine because it makes it possible for the model to take part of large theory knowledge. Below are some functions to use an opening book in pgn format. Also searching in the opening book for matching moves in order to make it more dynamic. When choosing move, it might select a random move out of the matching openings in order to make the games less deterministic and more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openings_from_pgn(pgn_file):\n",
    "    openings = []\n",
    "    with open(pgn_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            moves = []\n",
    "            for move in game.mainline_moves():\n",
    "                moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "\n",
    "            openings.append(moves)\n",
    "    return openings\n",
    "\n",
    "#Function to find matching openings based on played moves\n",
    "def find_matching_openings(played_moves, openings):\n",
    "    \"\"\"\n",
    "    Finding opening works by checking if the played moves match the start of any opening in the opening book.\n",
    "    This is because a chosen opening can be diverged from at any point by the opponent.\n",
    "    This makes the bot more dynamic in the opening phase.\n",
    "    \"\"\"\n",
    "    matching_openings = []\n",
    "    for opening in openings:\n",
    "        if played_moves == opening[:len(played_moves)]:\n",
    "            matching_openings.append(opening)\n",
    "    return matching_openings\n",
    "\n",
    "#Function to choose the next move from matching openings\n",
    "def select_next_move(played_moves, matching_openings, rand = True):\n",
    "    if not matching_openings:\n",
    "        return None  # No matching opening found, time for engine\n",
    "\n",
    "    \n",
    "    if rand:\n",
    "        chosen_opening = random.choice(matching_openings)\n",
    "\n",
    "        if len(chosen_opening) > len(played_moves):\n",
    "            next_move = chosen_opening[len(played_moves)]\n",
    "            return next_move\n",
    "    else:\n",
    "        for opening in matching_openings:\n",
    "            if len(opening) > len(played_moves):\n",
    "                next_move = opening[len(played_moves)]\n",
    "                return next_move\n",
    "    return None  # No more moves in the opening book, time for engine\n",
    "\n",
    "#Load the openings\n",
    "openings = load_openings_from_pgn(\"eco.pgn\")\n",
    "\n",
    "#Example usage\n",
    "played_moves = [\"e4\"]  \n",
    "matching_openings = find_matching_openings(played_moves, openings)\n",
    "next_move = select_next_move(played_moves, matching_openings)\n",
    "\n",
    "if next_move:\n",
    "    print(f\"Bot's next move: {next_move}\")\n",
    "else:\n",
    "    print(\"No matching opening found, calculate the move using engine logic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture is a CNN-Transformer. The CNN part is used to extract features from the board state and the Transformer part is used to make predictions based on the features extracted by the CNN. This is a powerful architecture when dealing with chess because it can learn to recognize patterns in the board state and make predictions based on those patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, padding=1) # 13 channels for the 12 piece types and an extra channel for the color the bot is playing\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.res_conv1 = nn.Conv2d(13, 64, kernel_size=1)  # To match channels for residual\n",
    "        self.res_conv2 = nn.Conv2d(64, 128, kernel_size=1)  # To match channels for residual\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=16)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=3)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.res_conv1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x + residual\n",
    "       # x += F.interpolate(residual, size=x.shape[2:]) \n",
    "\n",
    "        residual = self.res_conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x + residual\n",
    "\n",
    "        residual = x\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = x + residual\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "#Positional encoding for the transformer in order to give the model information about the position of the pieces\n",
    "#Uses the sine and cosine functions to encode the position of the board in a unique way\n",
    "#Experimental, might be overkill. Saw somewhere it could be useful for the transformer, but not sure if it is properly implemented here\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, d_model, 2).float()\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding = self.encoding.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:x.size(0), :].to(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old model that used 12 channels in the input convolutional layer instead of 13, because I was stupid and did not clarify for the engine which side it was playing. Code is still here for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNetOld(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNetOld, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, padding=1) # 13 channels for the 12 piece types and an extra channel for the color the bot is playing\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.res_conv1 = nn.Conv2d(13, 64, kernel_size=1)  # To match channels for residual\n",
    "        self.res_conv2 = nn.Conv2d(64, 128, kernel_size=1)  # To match channels for residual\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.res_conv1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += F.interpolate(residual, size=x.shape[2:]) \n",
    "\n",
    "        residual = self.res_conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += residual  \n",
    "\n",
    "        residual = x\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop and some functions for training the model is coded below. Using cross entropy loss and Adam optimizer, the model becomes pretty good at predicting the elite player's move in a given board state. Moves are also skipped in the beginning of the games to not unfairly punish the model for not predicting the first moves correctly, since most opening moves are interchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_input(board, is_white):\n",
    "    board_planes = np.zeros((8, 8, 13), dtype=np.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    return board_planes\n",
    "\n",
    "def move_to_output(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training step with move skipping and batching\n",
    "def train_on_batch(games, model, optimizer, criterion, device, skip_moves=10):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "\n",
    "    for game_str in games:\n",
    "        pgn_io = io.StringIO(game_str)\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        board = game.board()\n",
    "        move_count = 0\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            #A static number of moves are skipped to avoid overfitting to the opening book\n",
    "            #More sophisticated methods can be used to skip exact amount of book moves, but it is too inefficient for my machine\n",
    "            if move_count < skip_moves:\n",
    "                board.push(move)\n",
    "                move_count += 1\n",
    "                continue\n",
    "\n",
    "            #Prepare the input and output\n",
    "            is_white = board.turn == chess.WHITE\n",
    "            board_input = board_to_input(board, is_white)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            #Update the board with the actual move\n",
    "            board.push(move)\n",
    "\n",
    "        del pgn_io, game, board, move\n",
    "\n",
    "    if all_board_inputs:\n",
    "        #Stack all inputs and targets\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        del all_board_inputs, all_targets\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "        _, top3_pred = torch.topk(output, k=3, dim=1)  # Get the top-3 predictions\n",
    "        correct_moves_in_top3 = (top3_pred == batch_targets.unsqueeze(1)).sum(dim=1).float()\n",
    "        top3_accuracy = correct_moves_in_top3.mean().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del batch_inputs, batch_targets, output, top3_pred, correct_moves_in_top3, _\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves, top3_accuracy\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "#Training loop\n",
    "batch_size = 1024\n",
    "game_batch_size = 16 \n",
    "offset = 0\n",
    "step = 0\n",
    "j = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/updated_again_model_current.pth')) #Load the model from the previous training session\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    games = session.query(ChessGame).offset(offset).limit(batch_size).all()\n",
    "    if not games:\n",
    "        break\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    total_top3_accuracy = 0.0\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(games) // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        \n",
    "        for i in range(0, len(games), game_batch_size):\n",
    "            if offset // batch_size + 1 <2019:\n",
    "                break\n",
    "            game_batch = [game.pgn for game in games[i:i + game_batch_size]]\n",
    "            loss, accuracy, moves, top3_accuracy = train_on_batch(game_batch, model, optimizer, criterion, device, skip_moves=10)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_top3_accuracy += top3_accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves, 'Top-3 Accuracy': total_top3_accuracy / total_moves})\n",
    "\n",
    "            del game_batch, loss, accuracy, moves, top3_accuracy\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    j += 1\n",
    "    offset += batch_size\n",
    "    if offset // batch_size + 1 < 2019:\n",
    "        continue\n",
    "    if j % 25 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'updated_again_model_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    model_save_path = os.path.join('savedModels', f'updated_again_model_current.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "#Close the session and TensorBoard writer\n",
    "#Still have not tried TensorBoard, might not work\n",
    "session.close()\n",
    "model_save_path = os.path.join('savedModels', f'updated_again_model_final.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzles_df = pd.read_csv('../../Datasets/lichess_puzzle_transformed.csv')\n",
    "\n",
    "print(puzzles_df.head())\n",
    "len(puzzles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_puzzle_batch(puzzle_batch, model, optimizer, criterion, device):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "    # Loop through the dataframe in batches\n",
    "        \n",
    "\n",
    "    for _, row in puzzle_batch.iterrows():\n",
    "        # Extract FEN and move sequence\n",
    "        fen = row[2]\n",
    "        #print(fen)\n",
    "        move_sequence = row[3].split()\n",
    "        #print(move_sequence)\n",
    "        # Initialize the board from the starting FEN\n",
    "        board = chess.Board(fen)\n",
    "\n",
    "        # Process the sequence of moves one by one\n",
    "        for move in move_sequence:\n",
    "            # Convert the board to the input tensor\n",
    "\n",
    "            is_white = board.turn == chess.WHITE\n",
    "            board_input = board_to_input(board, is_white)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(chess.Move.from_uci(move))\n",
    "            #print(actual_output)\n",
    "            #print(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            # Apply the correct move to the board, so the next input is the real next position\n",
    "            board.push(chess.Move.from_uci(move))\n",
    "    \n",
    "    if all_board_inputs:\n",
    "        # Stack inputs and targets into tensors\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_moves = torch.argmax(output, dim=1)\n",
    "        accuracy = (predicted_moves == batch_targets).sum().item() / len(batch_targets)\n",
    "\n",
    "\n",
    "        del batch_inputs, batch_targets, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "batch_size = 4096\n",
    "game_batch_size = 64\n",
    "offset = 0\n",
    "step = 0\n",
    "j = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/puzzle_trained_current.pth')) #Load the model from the previous training session\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    #puzzles_df = pd.read_csv('../../Datasets/lichess_puzzle_transformed.csv')\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    \n",
    "    with tqdm(total=batch_size // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        \n",
    "        for i in range(0, batch_size, game_batch_size):\n",
    "            if offset // batch_size + 1 <100:\n",
    "                break\n",
    "            # Get the batch of puzzles\n",
    "            #i += offset\n",
    "            puzzle_batch = puzzles_df.iloc[i+offset:i+offset+game_batch_size]\n",
    "            #print(puzzle_batch.head())\n",
    "            loss, accuracy, moves = train_on_puzzle_batch(puzzle_batch, model, optimizer, criterion, device)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "\n",
    "            del loss, accuracy, moves, puzzle_batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            if i > offset + batch_size:\n",
    "                break\n",
    "    \n",
    "    j += 1\n",
    "    if j % 25 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'puzzle_trained_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    model_save_path = os.path.join('savedModels', f'puzzle_trained_current.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RL part is not implemented yet, but below is an attempt to create one. I believe the idea and strategy can be correct if properly implemented, but as of right now it is not working as well as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RL PART ######\n",
    "\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
    "\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "# Function to select a move given the current board position. Not currently used in the training loop whilst trying to fix some stuff\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0) \n",
    "\n",
    "    \n",
    "    logits = model(state) \n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    # Sample from moves based on the distribution of probabilities.\n",
    "    # In the early stages of training, the bot will explore many moves that it does not particularly prefer, \n",
    "    # but as the training progresses, the bot will start to get better, the distribution of probabilities of moves will more greatly favor the better moves, \n",
    "    # leading to less exploration.\n",
    "    move_idx = m.sample() \n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "# Function to simulate a batch of games of self-play\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = [board_to_input(boards[i]) for i in active_indices]\n",
    "        states = torch.cat(states).to(device)\n",
    "\n",
    "        \n",
    "        logits = model(states) \n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                print(\"All legal probabilities are zero\")\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx) \n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                #Greatly reward the bot for checkmating the opponent\n",
    "                rewards[i].append(5)\n",
    "                break\n",
    "\n",
    "            # If too many moves, break\n",
    "            if len(rewards[i]) > 200:\n",
    "                boards[i].push(chess.Move.null())\n",
    "                # Penalize the bot for taking too many moves\n",
    "                rewards[i][-1] -= 0.5\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i]\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "        \n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01 # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1 \n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1  \n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5  \n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5  \n",
    "\n",
    "    del states, logits, probabilities\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return log_probs, rewards, checkmate_count\n",
    "\n",
    "\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "# Function to assign value to pieces TODO: fix right values since these are maybe not good\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 0.1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 0.3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 0.5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 0.9\n",
    "    return 0\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, gamma=0.99):\n",
    "    policy_loss = 0\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns, dtype=torch.float32, requires_grad=False).to(device) # requires_grad=False since having problems with torch.no_grad during self-play. Trying to fix it\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            policy_loss += -log_prob * R\n",
    "\n",
    "    return policy_loss\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=4, accumulation_steps=4):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
    "    total_checkmates = 0\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        episode_loss = 0\n",
    "\n",
    "        for _ in range(accumulation_steps):\n",
    "            log_probs_batch, rewards_batch, checkmate_count = play_batch_games(model, batch_size)\n",
    "            \n",
    "            # Ensure autocast is used only during forward pass\n",
    "            with autocast(device_type=\"cuda\"):  # Enable mixed precision during policy update\n",
    "                policy_loss = update_policy_batch(log_probs_batch, rewards_batch, optimizer)\n",
    "\n",
    "                # Accumulate the loss\n",
    "                episode_loss += policy_loss / accumulation_steps\n",
    "\n",
    "        # Check that episode_loss requires gradients\n",
    "       # assert episode_loss.requires_grad, \"episode_loss does not require gradients.\"\n",
    "\n",
    "        # Backward pass with scaled gradients after accumulation\n",
    "        scaler.scale(episode_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_checkmates += checkmate_count  #Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates / (episode + 1) * batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=16, accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attempt at RL below, skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth'))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Functions to convert board states and moves\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input.to(device)\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 9\n",
    "    return 0\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "def center_control(board):\n",
    "    central_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "    control_score = 0\n",
    "\n",
    "    for square in central_squares:\n",
    "        attackers = board.attackers(chess.WHITE, square)\n",
    "        defenders = board.attackers(chess.BLACK, square)\n",
    "\n",
    "        if len(attackers) > len(defenders):\n",
    "            control_score += 0.1\n",
    "        elif len(attackers) < len(defenders):\n",
    "            control_score -= 0.1\n",
    "\n",
    "    return control_score\n",
    "\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(state)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    move_idx = m.sample()\n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "def dynamic_gamma(move_count):\n",
    "    if move_count < 20:\n",
    "        return 0.95  # Early game\n",
    "    elif move_count < 40:\n",
    "        return 0.98  # Mid game\n",
    "    else:\n",
    "        return 0.99  # End game\n",
    "\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    move_count = 0\n",
    "\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = torch.cat([board_to_input(boards[i]) for i in active_indices])\n",
    "\n",
    "        logits = model(states)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx)\n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            current_control_score = center_control(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i] + current_control_score\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "            move_count += 1\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "\n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01  # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5\n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5\n",
    "\n",
    "    return log_probs, rewards, checkmate_count, move_count\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count):\n",
    "    optimizer.zero_grad()\n",
    "    gamma = dynamic_gamma(move_count)\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns).to(device)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            loss = -log_prob * R\n",
    "            scaler.scale(loss).backward(retain_graph=True)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4):\n",
    "    model.train()\n",
    "    total_checkmates = 0\n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        log_probs_batch, rewards_batch, checkmate_count, move_count = play_batch_games(model, batch_size)\n",
    "        update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count)\n",
    "\n",
    "        total_checkmates += checkmate_count  # Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates/(episode+1)*batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Start training\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can play against the engine. It is painstakingly annoying to play, since there is no real UI and you have to input the moves in uci format. Will fix integration with the chess game and UI soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = ChessNet()\n",
    "model.load_state_dict(torch.load('savedModels/updated_again_model_current.pth'))\n",
    "model.eval()\n",
    "\n",
    "board = chess.Board()\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 13), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    \n",
    "    is_white = board.turn == chess.WHITE\n",
    "    board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    \n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "    return board_input\n",
    "\n",
    "def predict_move(model, board):\n",
    "    board_input = board_to_input(board)\n",
    "    with torch.no_grad():\n",
    "        output = model(board_input)\n",
    "    \n",
    "    move_scores = output.squeeze().sort(descending=True)\n",
    "    move_indices = move_scores.indices.tolist()\n",
    "    \n",
    "    for move_index in move_indices:\n",
    "        from_square = move_index // 64\n",
    "        to_square = move_index % 64\n",
    "        move = chess.Move(from_square, to_square)\n",
    "        #if pawn and last character is 1 or eight, add 'q' to the move\n",
    "        #Hopefully this works, always promotes to queen\n",
    "        if board.piece_at(from_square).piece_type == 1 and (str(move)[-1] == '1' or str(move)[-1] == '8'):\n",
    "            move = chess.Move(from_square, to_square, promotion=5) \n",
    "        print(move, move_scores.values[move_index].item())\n",
    "        \n",
    "        if move in board.legal_moves:\n",
    "            return move\n",
    "    \n",
    "    # If no valid moves are found (which shouldn't happen), return None\n",
    "    return None\n",
    "\n",
    "played_moves = []\n",
    "opening_phase = True\n",
    "player_white = False\n",
    "first_move_done = False\n",
    "while not board.is_game_over():\n",
    "    display(board)  \n",
    "    \n",
    "\n",
    "    if player_white or first_move_done:\n",
    "        user_move = input(\"Your move: \")\n",
    "        try:\n",
    "            move = chess.Move.from_uci(user_move)\n",
    "            if move in board.legal_moves:\n",
    "                played_moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "            else:\n",
    "                print(\"Invalid move. Try again.\")\n",
    "                continue\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Use UCI format (e.g., e2e4).\")\n",
    "            continue\n",
    "\n",
    "    if board.is_game_over():\n",
    "        break\n",
    "    #Get the bots move\n",
    "    if opening_phase:\n",
    "        matching_openings = find_matching_openings(played_moves, openings)\n",
    "        next_move = select_next_move(played_moves, matching_openings)\n",
    "    if opening_phase and next_move:\n",
    "        print(\"a\")\n",
    "        played_moves.append(next_move)\n",
    "        move = board.parse_san(next_move)\n",
    "        board.push(move)\n",
    "    else:\n",
    "        bot_move = predict_move(model, board)\n",
    "        opening_phase = False\n",
    "        if bot_move:\n",
    "            board.push(bot_move)\n",
    "        else:\n",
    "            print(\"Bot could not find a valid move.\")\n",
    "            break\n",
    "    first_move_done = True\n",
    "\n",
    "print(\"Game over!\")\n",
    "print(f\"Result: {board.result()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/updated_again_model_1625.pth'))\n",
    "model.eval()\n",
    "\n",
    "modelOld = ChessNet().to(device)\n",
    "modelOld.load_state_dict(torch.load('savedModels/updated_again_model_current.pth'))\n",
    "\n",
    "#modelOld = ChessNetOld().to(device)\n",
    "#modelOld.load_state_dict(torch.load('savedModels/updated_model_2000.pth'))\n",
    "modelOld.eval()\n",
    "\n",
    "def save_game_to_pgn(board, result, filename=\"games.pgn\"):\n",
    "    game = chess.pgn.Game.from_board(board)\n",
    "    game.headers[\"Result\"] = result\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(str(game) + \"\\n\\n\")\n",
    "\n",
    "def board_to_input(board, param):\n",
    "    board_planes = torch.zeros((8, 8, param), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    \n",
    "    if param == 13:\n",
    "        is_white = board.turn == chess.WHITE\n",
    "        board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    \n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "\n",
    "    return board_input\n",
    "\n",
    "def predict_moves_batch(model, boards, param):\n",
    "    board_inputs = torch.cat([board_to_input(board, param) for board in boards]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(board_inputs)\n",
    "    \n",
    "    moves = []\n",
    "    for output, board in zip(outputs, boards):\n",
    "        move_scores = output.squeeze().sort(descending=True)\n",
    "        move_indices = move_scores.indices.tolist()\n",
    "\n",
    "        for move_index in move_indices:\n",
    "            from_square = move_index // 64\n",
    "            to_square = move_index % 64\n",
    "            move = chess.Move(from_square, to_square)\n",
    "            if board.piece_at(from_square) and board.piece_at(from_square).piece_type == chess.PAWN and (str(move)[-1] == '1' or str(move)[-1] == '8'):\n",
    "                move = chess.Move(from_square, to_square, promotion=chess.QUEEN)\n",
    "\n",
    "            if move in board.legal_moves:\n",
    "                moves.append(move)\n",
    "                break\n",
    "        else:\n",
    "            moves.append(None)  # No valid move found\n",
    "    return moves\n",
    "\n",
    "def play_games_in_batch(model_white, model_black, batch_size, new_num_layers, pgn_filename=\"games.pgn\"):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    active = [True] * batch_size\n",
    "    results = []\n",
    "    played_moves_list = [[] for _ in range(batch_size)]  # Track the played moves for each game\n",
    "\n",
    "    while any(active):\n",
    "        # White's moves\n",
    "        white_moves = []\n",
    "        for i in range(batch_size):\n",
    "            if active[i]:\n",
    "                matching_openings = find_matching_openings(played_moves_list[i], openings)\n",
    "                next_move = select_next_move(played_moves_list[i], matching_openings)\n",
    "                print(next_move)\n",
    "                if next_move:\n",
    "                    print(boards[i])\n",
    "                    print(next_move)\n",
    "                    print(i)\n",
    "                \n",
    "                    move = boards[i].parse_san(next_move)\n",
    "                    print(move)\n",
    "                    \n",
    "                    white_moves.append(move)\n",
    "                else:\n",
    "                    white_moves.append(predict_moves_batch(model_white, [boards[i]], 13)[0])\n",
    "            else:\n",
    "                white_moves.append(None)\n",
    "\n",
    "        for i, move in enumerate(white_moves):\n",
    "            if active[i]:\n",
    "                if move:\n",
    "                    print(i)\n",
    "                    print(boards[i])\n",
    "                    print(move)\n",
    "                    \n",
    "                    played_moves_list[i].append(boards[i].san(move))\n",
    "                    boards[i].push(move) \n",
    "                \n",
    "                if boards[i].is_checkmate(): \n",
    "                    result = \"1-0\" \n",
    "                    active[i] = False\n",
    "                    results.append(result)\n",
    "                    save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "                elif boards[i].is_game_over():\n",
    "                    result = \"1/2-1/2\"\n",
    "                    print(result)\n",
    "                    active[i] = False\n",
    "                    results.append(result)\n",
    "                    save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "        print(\"b\")\n",
    "        # Black's moves\n",
    "        if any(active):\n",
    "            black_moves = []\n",
    "            for i in range(batch_size):\n",
    "                if active[i]:\n",
    "                    matching_openings = find_matching_openings(played_moves_list[i], openings)\n",
    "                    next_move = select_next_move(played_moves_list[i], matching_openings)\n",
    "                    if next_move:\n",
    "                        print(boards[i])\n",
    "                        print(next_move)\n",
    "                        move = boards[i].parse_san(next_move)\n",
    "                        black_moves.append(move)\n",
    "                        print(move)\n",
    "                    else:\n",
    "                        #print(i)\n",
    "                        black_moves.append(predict_moves_batch(model_black, [boards[i]], 13)[0])\n",
    "                else:\n",
    "                    black_moves.append(None)\n",
    "\n",
    "            for i, move in enumerate(black_moves):\n",
    "                if active[i]:\n",
    "                    if move:\n",
    "                        played_moves_list[i].append(boards[i].san(move))\n",
    "                        boards[i].push(move)\n",
    "                        \n",
    "                    if boards[i].is_checkmate(): \n",
    "                        result = \"0-1\" \n",
    "                        active[i] = False\n",
    "                        results.append(result)\n",
    "                        save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "\n",
    "                    elif boards[i].is_game_over():\n",
    "                        result = \"1/2-1/2\"\n",
    "                        print(result)\n",
    "                        active[i] = False\n",
    "                        results.append(result)\n",
    "                        save_game_to_pgn(boards[i], result, pgn_filename)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the batch of games\n",
    "total_games = 320\n",
    "batch_size = 32 \n",
    "results = {'new_model_wins': 0, 'old_model_wins': 0, 'draws': 0}\n",
    "\n",
    "# First 500 games: new model as White, old model as Black\n",
    "for i in range(0, total_games//2, batch_size):\n",
    "    batch_results = play_games_in_batch(model, modelOld, min(batch_size, 500 - i), True)\n",
    "    \n",
    "    for result in batch_results:\n",
    "        if result == '1-0':\n",
    "            results['new_model_wins'] += 1\n",
    "        elif result == '0-1':\n",
    "            results['old_model_wins'] += 1\n",
    "        else:\n",
    "            results['draws'] += 1\n",
    "\n",
    "# Second 500 games: old model as White, new model as Black\n",
    "for i in range(0, total_games//2, batch_size):\n",
    "    batch_results = play_games_in_batch(modelOld, model, min(batch_size, 500 - i), True)\n",
    "    \n",
    "    for result in batch_results:\n",
    "        if result == '1-0':\n",
    "            results['old_model_wins'] += 1\n",
    "        elif result == '0-1':\n",
    "            results['new_model_wins'] += 1\n",
    "        else:\n",
    "            results['draws'] += 1\n",
    "\n",
    "print(\"Simulation complete!\")\n",
    "print(f\"New Model Wins: {results['new_model_wins']}\")\n",
    "print(f\"Old Model Wins: {results['old_model_wins']}\")\n",
    "print(f\"Draws: {results['draws']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell is used to check weights and structurtes in models\n",
    "\n",
    "state_dict = torch.load('savedModels/updated_model_2000.pth')\n",
    "\n",
    "print(\"Model layers and parameters in the .pth file:\")\n",
    "for key in state_dict.keys():\n",
    "    print(key)\n",
    "\n",
    "print(\"\\nLayer names and weight shapes:\")\n",
    "for key, value in state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
