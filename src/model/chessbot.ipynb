{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import math\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_23696\\736078126.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ChessGame(Base):\n",
    "    __tablename__ = 'games'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pgn = Column(Text)\n",
    "\n",
    "engine = create_engine('sqlite:///../chess_games.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's next move: g6\n"
     ]
    }
   ],
   "source": [
    "def load_openings_from_pgn(pgn_file):\n",
    "    openings = []\n",
    "    with open(pgn_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            moves = []\n",
    "            for move in game.mainline_moves():\n",
    "                moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "\n",
    "            openings.append(moves)\n",
    "    return openings\n",
    "\n",
    "#Function to find matching openings based on played moves\n",
    "def find_matching_openings(played_moves, openings):\n",
    "    \"\"\"\n",
    "    Finding opening works by checking if the played moves match the start of any opening in the opening book.\n",
    "    This is because a chosen opening can be diverged from at any point by the opponent.\n",
    "    This makes the bot more dynamic in the opening phase.\n",
    "    \"\"\"\n",
    "    matching_openings = []\n",
    "    for opening in openings:\n",
    "        if played_moves == opening[:len(played_moves)]:\n",
    "            matching_openings.append(opening)\n",
    "    return matching_openings\n",
    "\n",
    "#Function to choose the next move from matching openings\n",
    "def select_next_move(played_moves, matching_openings):\n",
    "    if not matching_openings:\n",
    "        return None  # No matching opening found, time for engine\n",
    "\n",
    "    # Check if there is a next move available in the matching opening\n",
    "    for opening in matching_openings:\n",
    "        if len(opening) > len(played_moves):\n",
    "            next_move = opening[len(played_moves)]\n",
    "            return next_move\n",
    "    \n",
    "    return None  # No more moves in the opening book, time for engine\n",
    "\n",
    "#Load the openings\n",
    "openings = load_openings_from_pgn(\"eco.pgn\")\n",
    "\n",
    "#Example usage\n",
    "played_moves = ['e4']  \n",
    "matching_openings = find_matching_openings(played_moves, openings)\n",
    "next_move = select_next_move(played_moves, matching_openings)\n",
    "\n",
    "if next_move:\n",
    "    print(f\"Bot's next move: {next_move}\")\n",
    "else:\n",
    "    print(\"No matching opening found, calculate the move using engine logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, padding=1) # 13 channels for the 12 piece types and an extra channel for the color the bot is playing\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "#Positional encoding for the transformer in order to give the model information about the position of the pieces\n",
    "#Uses the sine and cosine functions to encode the position of the board in a unique way\n",
    "#Experimental, might be overkill. Saw somewhere it could be useful for the transformer, but not sure if it is properly implemented here\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, d_model, 2).float()\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding = self.encoding.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:x.size(0), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Processing Batch 1:   0%|          | 0/64 [00:00<?, ?it/s]c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Processing Batch 1: 100%|██████████| 64/64 [00:34<00:00,  1.86it/s, Loss=7.37, Accuracy=0.0152] \n",
      "Processing Batch 2: 100%|██████████| 64/64 [00:32<00:00,  1.95it/s, Loss=5.65, Accuracy=0.0714]\n",
      "Processing Batch 3: 100%|██████████| 64/64 [00:31<00:00,  2.01it/s, Loss=4.12, Accuracy=0.131]\n",
      "Processing Batch 4: 100%|██████████| 64/64 [00:32<00:00,  1.95it/s, Loss=3.72, Accuracy=0.159]\n",
      "Processing Batch 5: 100%|██████████| 64/64 [00:33<00:00,  1.93it/s, Loss=3.51, Accuracy=0.18] \n",
      "Processing Batch 6: 100%|██████████| 64/64 [00:35<00:00,  1.82it/s, Loss=3.35, Accuracy=0.195]\n",
      "Processing Batch 7: 100%|██████████| 64/64 [00:38<00:00,  1.66it/s, Loss=3.22, Accuracy=0.207]\n",
      "Processing Batch 8: 100%|██████████| 64/64 [00:34<00:00,  1.83it/s, Loss=3.15, Accuracy=0.215]\n",
      "Processing Batch 9: 100%|██████████| 64/64 [00:34<00:00,  1.87it/s, Loss=3.07, Accuracy=0.222]\n",
      "Processing Batch 10: 100%|██████████| 64/64 [00:35<00:00,  1.80it/s, Loss=2.99, Accuracy=0.234]\n",
      "Processing Batch 11: 100%|██████████| 64/64 [00:35<00:00,  1.82it/s, Loss=2.94, Accuracy=0.244]\n",
      "Processing Batch 12: 100%|██████████| 64/64 [00:34<00:00,  1.83it/s, Loss=2.9, Accuracy=0.248] \n",
      "Processing Batch 13: 100%|██████████| 64/64 [00:34<00:00,  1.85it/s, Loss=2.86, Accuracy=0.252]\n",
      "Processing Batch 14: 100%|██████████| 64/64 [00:33<00:00,  1.90it/s, Loss=2.82, Accuracy=0.259]\n",
      "Processing Batch 15: 100%|██████████| 64/64 [00:32<00:00,  1.94it/s, Loss=2.79, Accuracy=0.266]\n",
      "Processing Batch 16: 100%|██████████| 64/64 [00:36<00:00,  1.77it/s, Loss=2.77, Accuracy=0.269]\n",
      "Processing Batch 17: 100%|██████████| 64/64 [00:31<00:00,  2.04it/s, Loss=2.73, Accuracy=0.274]\n",
      "Processing Batch 18:  94%|█████████▍| 60/64 [00:30<00:02,  1.95it/s, Loss=2.7, Accuracy=0.279] "
     ]
    }
   ],
   "source": [
    "def board_to_input(board, is_white):\n",
    "    board_planes = np.zeros((8, 8, 13), dtype=np.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_planes[:, :, 12] = 1.0 if is_white else 0.0\n",
    "    return board_planes\n",
    "\n",
    "#Encode the move TODO: Make it possible to encode promotion moves. ATM it only encodes the move from and to square and is unable to promote.\n",
    "def move_to_output(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "#Training step with move skipping and batching\n",
    "def train_on_batch(games, model, optimizer, criterion, device, skip_moves=10):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "\n",
    "    for game_str in games:\n",
    "        pgn_io = io.StringIO(game_str)\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        board = game.board()\n",
    "        move_count = 0\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            #A static number of moves are skipped to avoid overfitting to the opening book\n",
    "            #More sophisticated methods can be used to skip exact amount of book moves, but it is too inefficient for my machine\n",
    "            if move_count < skip_moves:\n",
    "                board.push(move)\n",
    "                move_count += 1\n",
    "                continue\n",
    "\n",
    "            #Prepare the input and output\n",
    "            is_white = board.turn == chess.WHITE\n",
    "            board_input = board_to_input(board, is_white)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            #Update the board with the actual move\n",
    "            board.push(move)\n",
    "\n",
    "    if all_board_inputs:\n",
    "        #Stack all inputs and targets\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del batch_inputs, batch_targets, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "#Training loop\n",
    "batch_size = 1024\n",
    "game_batch_size = 16 \n",
    "offset = 0\n",
    "step = 0\n",
    "j = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "#model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth')) #Load the model from the previous training session\n",
    "#model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    games = session.query(ChessGame).offset(offset).limit(batch_size).all()\n",
    "    if not games:\n",
    "        break\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(games) // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        \n",
    "        for i in range(0, len(games), game_batch_size):\n",
    "            #if offset // batch_size + 1 <63:\n",
    "                #break\n",
    "            game_batch = [game.pgn for game in games[i:i + game_batch_size]]\n",
    "            loss, accuracy, moves = train_on_batch(game_batch, model, optimizer, criterion, device, skip_moves=10)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "\n",
    "            del game_batch, loss, accuracy, moves\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    j += 1\n",
    "    if j % 25 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'new_model_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    model_save_path = os.path.join('savedModels', f'new_model_current.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n",
    "    \n",
    "#Close the session and TensorBoard writer\n",
    "#Still have not tried TensorBoard, might not work\n",
    "session.close()\n",
    "model_save_path = os.path.join('savedModels', f'new_model_final.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_34488\\4067602970.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
      "Training Progress:   0%|          | 0/1000 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 10.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 238\u001b[0m\n\u001b[0;32m    234\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_path)\n\u001b[0;32m    236\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m--> 238\u001b[0m \u001b[43mtrain_self_play_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 207\u001b[0m, in \u001b[0;36mtrain_self_play_batch\u001b[1;34m(model, optimizer, num_episodes, batch_size, accumulation_steps)\u001b[0m\n\u001b[0;32m    204\u001b[0m episode_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(accumulation_steps):\n\u001b[1;32m--> 207\u001b[0m     log_probs_batch, rewards_batch, checkmate_count \u001b[38;5;241m=\u001b[39m \u001b[43mplay_batch_games\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Ensure autocast is used only during forward pass\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Enable mixed precision during policy update\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 66\u001b[0m, in \u001b[0;36mplay_batch_games\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m states \u001b[38;5;241m=\u001b[39m [board_to_input(boards[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m active_indices]\n\u001b[0;32m     63\u001b[0m states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(states)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 66\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     67\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(active_indices):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mChessNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(x)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Transformer encoder\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m#[batch_size, sequence_length, d_model]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    413\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 416\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    419\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:750\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[1;32m--> 750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:765\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 765\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 10.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "###### RL PART ######\n",
    "\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
    "\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "# Function to select a move given the current board position. Not currently used in the training loop whilst trying to fix some stuff\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0) \n",
    "\n",
    "    \n",
    "    logits = model(state) \n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    # Sample from moves based on the distribution of probabilities.\n",
    "    # In the early stages of training, the bot will explore many moves that it does not particularly prefer, \n",
    "    # but as the training progresses, the bot will start to get better, the distribution of probabilities of moves will more greatly favor the better moves, \n",
    "    # leading to less exploration.\n",
    "    move_idx = m.sample() \n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "# Function to simulate a batch of games of self-play\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = [board_to_input(boards[i]) for i in active_indices]\n",
    "        states = torch.cat(states).to(device)\n",
    "\n",
    "        \n",
    "        logits = model(states) \n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                print(\"All legal probabilities are zero\")\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx) \n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                #Greatly reward the bot for checkmating the opponent\n",
    "                rewards[i].append(5)\n",
    "                break\n",
    "\n",
    "            # If too many moves, break\n",
    "            if len(rewards[i]) > 200:\n",
    "                boards[i].push(chess.Move.null())\n",
    "                # Penalize the bot for taking too many moves\n",
    "                rewards[i][-1] -= 0.5\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i]\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "        \n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01 # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1 \n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1  \n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5  \n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5  \n",
    "\n",
    "    del states, logits, probabilities\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return log_probs, rewards, checkmate_count\n",
    "\n",
    "\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "# Function to assign value to pieces TODO: fix right values since these are maybe not good\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 0.1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 0.3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 0.5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 0.9\n",
    "    return 0\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, gamma=0.99):\n",
    "    policy_loss = 0\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns, dtype=torch.float32, requires_grad=False).to(device) # requires_grad=False since having problems with torch.no_grad during self-play. Trying to fix it\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            policy_loss += -log_prob * R\n",
    "\n",
    "    return policy_loss\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=4, accumulation_steps=4):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
    "    total_checkmates = 0\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        episode_loss = 0\n",
    "\n",
    "        for _ in range(accumulation_steps):\n",
    "            log_probs_batch, rewards_batch, checkmate_count = play_batch_games(model, batch_size)\n",
    "            \n",
    "            # Ensure autocast is used only during forward pass\n",
    "            with autocast(device_type=\"cuda\"):  # Enable mixed precision during policy update\n",
    "                policy_loss = update_policy_batch(log_probs_batch, rewards_batch, optimizer)\n",
    "\n",
    "                # Accumulate the loss\n",
    "                episode_loss += policy_loss / accumulation_steps\n",
    "\n",
    "        # Check that episode_loss requires gradients\n",
    "       # assert episode_loss.requires_grad, \"episode_loss does not require gradients.\"\n",
    "\n",
    "        # Backward pass with scaled gradients after accumulation\n",
    "        scaler.scale(episode_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_checkmates += checkmate_count  #Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates / (episode + 1) * batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=16, accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_38924\\3267276009.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth'))\n",
      "Training Progress:   0%|          | 0/1000 [00:05<?, ?it/s]\n",
      "Exception ignored in: <function tqdm.__del__ at 0x0000019E6CF56480>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1267, in close\n",
      "    if self.disable:\n",
      "       ^^^^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disable'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 230\u001b[0m\n\u001b[0;32m    227\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[43mtrain_self_play_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 211\u001b[0m, in \u001b[0;36mtrain_self_play_batch\u001b[1;34m(model, optimizer, num_episodes, batch_size, accumulate_grad_steps)\u001b[0m\n\u001b[0;32m    208\u001b[0m total_checkmates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_episodes), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     log_probs_batch, rewards_batch, checkmate_count, move_count \u001b[38;5;241m=\u001b[39m \u001b[43mplay_batch_games\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count)\n\u001b[0;32m    214\u001b[0m     total_checkmates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m checkmate_count  \u001b[38;5;66;03m# Count checkmates as metric for progress in early stages\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 132\u001b[0m, in \u001b[0;36mplay_batch_games\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m    128\u001b[0m     legal_probabilities \u001b[38;5;241m=\u001b[39m mask  \u001b[38;5;66;03m# fallback to uniform distribution over legal moves\u001b[39;00m\n\u001b[0;32m    130\u001b[0m legal_probabilities \u001b[38;5;241m=\u001b[39m legal_probabilities \u001b[38;5;241m/\u001b[39m legal_probabilities\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlegal_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m move_idx \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m    135\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mlog_prob(move_idx)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\distributions\\categorical.py:71\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     68\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m     70\u001b[0m )\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\distributions\\distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip checking lazily-constructed args\u001b[39;00m\n\u001b[0;32m     67\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m---> 68\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\distributions\\constraints.py:441\u001b[0m, in \u001b[0;36m_Simplex.check\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(value \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming your ChessNet model is defined elsewhere\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth'))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Functions to convert board states and moves\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input.to(device)\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 9\n",
    "    return 0\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "def center_control(board):\n",
    "    central_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "    control_score = 0\n",
    "\n",
    "    for square in central_squares:\n",
    "        attackers = board.attackers(chess.WHITE, square)\n",
    "        defenders = board.attackers(chess.BLACK, square)\n",
    "\n",
    "        if len(attackers) > len(defenders):\n",
    "            control_score += 0.1\n",
    "        elif len(attackers) < len(defenders):\n",
    "            control_score -= 0.1\n",
    "\n",
    "    return control_score\n",
    "\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(state)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    move_idx = m.sample()\n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "def dynamic_gamma(move_count):\n",
    "    if move_count < 20:\n",
    "        return 0.95  # Early game\n",
    "    elif move_count < 40:\n",
    "        return 0.98  # Mid game\n",
    "    else:\n",
    "        return 0.99  # End game\n",
    "\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    move_count = 0\n",
    "\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = torch.cat([board_to_input(boards[i]) for i in active_indices])\n",
    "\n",
    "        logits = model(states)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx)\n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            current_control_score = center_control(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i] + current_control_score\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "            move_count += 1\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "\n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01  # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5\n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5\n",
    "\n",
    "    return log_probs, rewards, checkmate_count, move_count\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count):\n",
    "    optimizer.zero_grad()\n",
    "    gamma = dynamic_gamma(move_count)\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns).to(device)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            loss = -log_prob * R\n",
    "            scaler.scale(loss).backward(retain_graph=True)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4):\n",
    "    model.train()\n",
    "    total_checkmates = 0\n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        log_probs_batch, rewards_batch, checkmate_count, move_count = play_batch_games(model, batch_size)\n",
    "        update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count)\n",
    "\n",
    "        total_checkmates += checkmate_count  # Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates/(episode+1)*batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Start training\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add opening book moves to the bot, for some reason not here anymore after adding it???\n",
    "\n",
    "model = ChessNet()\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_current.pth'))\n",
    "model.eval()\n",
    "\n",
    "board = chess.Board()\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "    return board_input\n",
    "\n",
    "def predict_move(model, board):\n",
    "    board_input = board_to_input(board)\n",
    "    with torch.no_grad():\n",
    "        output = model(board_input)\n",
    "    \n",
    "    move_scores = output.squeeze().sort(descending=True)\n",
    "    move_indices = move_scores.indices.tolist()\n",
    "    \n",
    "    for move_index in move_indices:\n",
    "        from_square = move_index // 64\n",
    "        to_square = move_index % 64\n",
    "        move = chess.Move(from_square, to_square)\n",
    "        #if pawn and last character is 1 or eight, add 'q' to the move\n",
    "        #Hopefully this works, always promotes to queen\n",
    "        if board.piece_at(from_square).piece_type == 1 and (str(move)[-1] == '1' or str(move)[-1] == '8'):\n",
    "            move = chess.Move(from_square, to_square, promotion=5) \n",
    "        print(move, move_scores.values[move_index].item())\n",
    "        \n",
    "        if move in board.legal_moves:\n",
    "            return move\n",
    "    \n",
    "    # If no valid moves are found (which shouldn't happen), return None\n",
    "    return None\n",
    "\n",
    "\n",
    "while not board.is_game_over():\n",
    "    display(board)  \n",
    "    user_move = input(\"Your move: \")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        move = chess.Move.from_uci(user_move)\n",
    "        if move in board.legal_moves:\n",
    "            board.push(move)\n",
    "        else:\n",
    "            print(\"Invalid move. Try again.\")\n",
    "            continue\n",
    "    except ValueError:\n",
    "        print(\"Invalid format. Use UCI format (e.g., e2e4).\")\n",
    "        continue\n",
    "\n",
    "    if board.is_game_over():\n",
    "        break\n",
    "\n",
    "    #Get the bots move\n",
    "    bot_move = predict_move(model, board)\n",
    "    if bot_move:\n",
    "        board.push(bot_move)\n",
    "        print(f\"Bot's move: {bot_move}\")\n",
    "    else:\n",
    "        print(\"Bot could not find a valid move.\")\n",
    "        break\n",
    "\n",
    "print(\"Game over!\")\n",
    "print(f\"Result: {board.result()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
