{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import math\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_45284\\736078126.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ChessGame(Base):\n",
    "    __tablename__ = 'games'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pgn = Column(Text)\n",
    "\n",
    "engine = create_engine('sqlite:///../chess_games.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's next move: g6\n"
     ]
    }
   ],
   "source": [
    "def load_openings_from_pgn(pgn_file):\n",
    "    openings = []\n",
    "    with open(pgn_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            moves = []\n",
    "            for move in game.mainline_moves():\n",
    "                moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "\n",
    "            openings.append(moves)\n",
    "    return openings\n",
    "\n",
    "#Function to find matching openings based on played moves\n",
    "def find_matching_openings(played_moves, openings):\n",
    "    \"\"\"\n",
    "    Finding opening works by checking if the played moves match the start of any opening in the opening book.\n",
    "    This is because a chosen opening can be diverged from at any point by the opponent.\n",
    "    This makes the bot more dynamic in the opening phase.\n",
    "    \"\"\"\n",
    "    matching_openings = []\n",
    "    for opening in openings:\n",
    "        if played_moves == opening[:len(played_moves)]:\n",
    "            matching_openings.append(opening)\n",
    "    return matching_openings\n",
    "\n",
    "#Function to choose the next move from matching openings\n",
    "def select_next_move(played_moves, matching_openings):\n",
    "    if not matching_openings:\n",
    "        return None  # No matching opening found, time for engine\n",
    "\n",
    "    # Check if there is a next move available in the matching opening\n",
    "    for opening in matching_openings:\n",
    "        if len(opening) > len(played_moves):\n",
    "            next_move = opening[len(played_moves)]\n",
    "            return next_move\n",
    "    \n",
    "    return None  # No more moves in the opening book, time for engine\n",
    "\n",
    "#Load the openings\n",
    "openings = load_openings_from_pgn(\"eco.pgn\")\n",
    "\n",
    "#Example usage\n",
    "played_moves = ['e4']  \n",
    "matching_openings = find_matching_openings(played_moves, openings)\n",
    "next_move = select_next_move(played_moves, matching_openings)\n",
    "\n",
    "if next_move:\n",
    "    print(f\"Bot's next move: {next_move}\")\n",
    "else:\n",
    "    print(\"No matching opening found, calculate the move using engine logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=4)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "#Positional encoding for the transformer in order to give the model information about the position of the pieces\n",
    "#Uses the sine and cosine functions to encode the position of the board in a unique way\n",
    "#Experimental, might be overkill. Saw somewhere it could be useful for the transformer, but not sure if it is properly implemented here\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, d_model, 2).float()\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding = self.encoding.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:x.size(0), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Processing Batch 1:   0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Processing Batch 1: 100%|██████████| 100/100 [03:14<00:00,  1.94s/it, Loss=8.02, Accuracy=0.00603]\n",
      "Processing Batch 2:  33%|███▎      | 33/100 [00:54<01:58,  1.77s/it, Loss=7.16, Accuracy=0.00807]"
     ]
    }
   ],
   "source": [
    "def board_to_input(board):\n",
    "    board_planes = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    return board_planes\n",
    "\n",
    "#Encode the move\n",
    "def move_to_output(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "#Training step with move skipping and batching\n",
    "def train_on_batch(games, model, optimizer, criterion, device, skip_moves=6):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "\n",
    "    for game_str in games:\n",
    "        pgn_io = io.StringIO(game_str)\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        board = game.board()\n",
    "        move_count = 0\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            #A static number of moves are skipped to avoid overfitting to the opening book\n",
    "            #More sophisticated methods can be used to skip exact amount of book moves, but it is too inefficient for my machine\n",
    "            if move_count < skip_moves:\n",
    "                board.push(move)\n",
    "                move_count += 1\n",
    "                continue\n",
    "\n",
    "            #Prepare the input and output\n",
    "            board_input = board_to_input(board)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            #Update the board with the actual move\n",
    "            board.push(move)\n",
    "\n",
    "    if all_board_inputs:\n",
    "        #Stack all inputs and targets\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "#Training loop\n",
    "batch_size = 1000\n",
    "game_batch_size = 10 \n",
    "offset = 0\n",
    "step = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    games = session.query(ChessGame).offset(offset).limit(batch_size).all()\n",
    "    if not games:\n",
    "        break\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    j = 0\n",
    "\n",
    "    with tqdm(total=len(games) // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        for i in range(0, len(games), game_batch_size):\n",
    "            game_batch = [game.pgn for game in games[i:i + game_batch_size]]\n",
    "            loss, accuracy, moves = train_on_batch(game_batch, model, optimizer, criterion, device, skip_moves=6)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "    j += 1\n",
    "    model_save_path = os.path.join('savedModels', f'cnn_transformer_model_epoch_{j}.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n",
    "    \n",
    "#Close the session and TensorBoard writer\n",
    "#Still have not tried TensorBoard, might not work\n",
    "session.close()\n",
    "model_save_path = os.path.join('savedModels', f'cnn_transformer_model_final.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
