{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import math\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_34488\\736078126.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ChessGame(Base):\n",
    "    __tablename__ = 'games'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pgn = Column(Text)\n",
    "\n",
    "engine = create_engine('sqlite:///../chess_games.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's next move: g6\n"
     ]
    }
   ],
   "source": [
    "def load_openings_from_pgn(pgn_file):\n",
    "    openings = []\n",
    "    with open(pgn_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            moves = []\n",
    "            for move in game.mainline_moves():\n",
    "                moves.append(board.san(move))\n",
    "                board.push(move)\n",
    "\n",
    "            openings.append(moves)\n",
    "    return openings\n",
    "\n",
    "#Function to find matching openings based on played moves\n",
    "def find_matching_openings(played_moves, openings):\n",
    "    \"\"\"\n",
    "    Finding opening works by checking if the played moves match the start of any opening in the opening book.\n",
    "    This is because a chosen opening can be diverged from at any point by the opponent.\n",
    "    This makes the bot more dynamic in the opening phase.\n",
    "    \"\"\"\n",
    "    matching_openings = []\n",
    "    for opening in openings:\n",
    "        if played_moves == opening[:len(played_moves)]:\n",
    "            matching_openings.append(opening)\n",
    "    return matching_openings\n",
    "\n",
    "#Function to choose the next move from matching openings\n",
    "def select_next_move(played_moves, matching_openings):\n",
    "    if not matching_openings:\n",
    "        return None  # No matching opening found, time for engine\n",
    "\n",
    "    # Check if there is a next move available in the matching opening\n",
    "    for opening in matching_openings:\n",
    "        if len(opening) > len(played_moves):\n",
    "            next_move = opening[len(played_moves)]\n",
    "            return next_move\n",
    "    \n",
    "    return None  # No more moves in the opening book, time for engine\n",
    "\n",
    "#Load the openings\n",
    "openings = load_openings_from_pgn(\"eco.pgn\")\n",
    "\n",
    "#Example usage\n",
    "played_moves = ['e4']  \n",
    "matching_openings = find_matching_openings(played_moves, openings)\n",
    "next_move = select_next_move(played_moves, matching_openings)\n",
    "\n",
    "if next_move:\n",
    "    print(f\"Bot's next move: {next_move}\")\n",
    "else:\n",
    "    print(\"No matching opening found, calculate the move using engine logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #Positional encoding for the transformer\n",
    "        self.positional_encoding = PositionalEncoding(d_model=128)\n",
    "\n",
    "        #Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(8*8*128, 4096)  #4096 possible moves\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 128, 8*8)  #[batch_size, d_model, sequence_length]\n",
    "        x = x.permute(2, 0, 1)  #[sequence_length, batch_size, d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2).contiguous()  #[batch_size, sequence_length, d_model]\n",
    "        x = x.view(-1, 8*8*128)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "#Positional encoding for the transformer in order to give the model information about the position of the pieces\n",
    "#Uses the sine and cosine functions to encode the position of the board in a unique way\n",
    "#Experimental, might be overkill. Saw somewhere it could be useful for the transformer, but not sure if it is properly implemented here\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        self.encoding.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, d_model, 2).float()\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding = self.encoding.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:x.size(0), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Processing Batch 1:   0%|          | 0/62 [00:00<?, ?it/s]c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Processing Batch 1: 63it [00:45,  1.38it/s, Loss=7.35, Accuracy=0.0152]                         \n",
      "Processing Batch 2: 63it [00:31,  2.02it/s, Loss=5.42, Accuracy=0.0669]                        \n",
      "Processing Batch 3: 63it [00:26,  2.39it/s, Loss=4.67, Accuracy=0.0981]                        \n",
      "Processing Batch 4: 63it [00:29,  2.12it/s, Loss=4.38, Accuracy=0.113]                        \n",
      "Processing Batch 5: 63it [00:28,  2.22it/s, Loss=4.19, Accuracy=0.125]                        \n",
      "Processing Batch 6: 63it [02:52,  2.74s/it, Loss=4.07, Accuracy=0.133]                        \n",
      "Processing Batch 7: 63it [02:14,  2.13s/it, Loss=3.95, Accuracy=0.142]                        \n",
      "Processing Batch 8: 63it [00:28,  2.23it/s, Loss=3.89, Accuracy=0.146]                        \n",
      "Processing Batch 9: 63it [00:29,  2.16it/s, Loss=3.82, Accuracy=0.151]                        \n",
      "Processing Batch 10: 63it [00:28,  2.21it/s, Loss=3.73, Accuracy=0.16]                         \n",
      "Processing Batch 11: 63it [00:29,  2.17it/s, Loss=3.69, Accuracy=0.163]                        \n",
      "Processing Batch 12: 63it [00:27,  2.25it/s, Loss=3.63, Accuracy=0.166]                        \n",
      "Processing Batch 13: 63it [00:28,  2.18it/s, Loss=3.61, Accuracy=0.169]                        \n",
      "Processing Batch 14: 63it [02:57,  2.82s/it, Loss=3.55, Accuracy=0.176]                        \n",
      "Processing Batch 15: 63it [03:01,  2.88s/it, Loss=3.52, Accuracy=0.183]                        \n",
      "Processing Batch 16: 63it [02:56,  2.80s/it, Loss=3.5, Accuracy=0.181]                         \n",
      "Processing Batch 17: 63it [00:46,  1.37it/s, Loss=3.45, Accuracy=0.189]                        \n",
      "Processing Batch 18: 63it [00:26,  2.34it/s, Loss=3.42, Accuracy=0.191]                        \n",
      "Processing Batch 19: 63it [00:26,  2.37it/s, Loss=3.38, Accuracy=0.196]                        \n",
      "Processing Batch 20: 63it [00:27,  2.30it/s, Loss=3.35, Accuracy=0.199]                        \n",
      "Processing Batch 21: 63it [00:27,  2.27it/s, Loss=3.34, Accuracy=0.201]                        \n",
      "Processing Batch 22: 63it [00:26,  2.35it/s, Loss=3.33, Accuracy=0.2]                          \n",
      "Processing Batch 23: 63it [00:27,  2.26it/s, Loss=3.33, Accuracy=0.198]                        \n",
      "Processing Batch 24: 63it [00:28,  2.24it/s, Loss=3.29, Accuracy=0.204]                        \n",
      "Processing Batch 25: 63it [00:27,  2.28it/s, Loss=3.27, Accuracy=0.209]                        \n",
      "Processing Batch 26: 63it [00:28,  2.18it/s, Loss=3.24, Accuracy=0.213]                        \n",
      "Processing Batch 27: 63it [00:27,  2.26it/s, Loss=3.25, Accuracy=0.208]                        \n",
      "Processing Batch 28: 63it [00:27,  2.29it/s, Loss=3.22, Accuracy=0.214]                        \n",
      "Processing Batch 29: 63it [00:27,  2.26it/s, Loss=3.24, Accuracy=0.21]                         \n",
      "Processing Batch 30: 63it [00:27,  2.27it/s, Loss=3.22, Accuracy=0.213]                        \n",
      "Processing Batch 31: 63it [00:27,  2.29it/s, Loss=3.21, Accuracy=0.214]                        \n",
      "Processing Batch 32: 63it [00:27,  2.28it/s, Loss=3.18, Accuracy=0.219]                        \n",
      "Processing Batch 33: 63it [00:27,  2.27it/s, Loss=3.17, Accuracy=0.217]                        \n",
      "Processing Batch 34: 63it [00:28,  2.24it/s, Loss=3.14, Accuracy=0.221]                        \n",
      "Processing Batch 35: 63it [00:27,  2.32it/s, Loss=3.12, Accuracy=0.228]                        \n",
      "Processing Batch 36: 63it [00:26,  2.36it/s, Loss=3.12, Accuracy=0.227]                        \n",
      "Processing Batch 37: 63it [00:27,  2.30it/s, Loss=3.13, Accuracy=0.225]                        \n",
      "Processing Batch 38: 63it [00:26,  2.34it/s, Loss=3.11, Accuracy=0.227]                        \n",
      "Processing Batch 39: 63it [00:28,  2.22it/s, Loss=3.11, Accuracy=0.227]                        \n",
      "Processing Batch 40: 63it [00:27,  2.32it/s, Loss=3.09, Accuracy=0.232]                        \n",
      "Processing Batch 41: 63it [00:28,  2.24it/s, Loss=3.08, Accuracy=0.232]                        \n",
      "Processing Batch 42: 63it [00:27,  2.28it/s, Loss=3.07, Accuracy=0.233]                        \n",
      "Processing Batch 43: 63it [00:28,  2.25it/s, Loss=3.08, Accuracy=0.231]                        \n",
      "Processing Batch 44: 63it [00:27,  2.33it/s, Loss=3.07, Accuracy=0.234]                        \n",
      "Processing Batch 45: 63it [00:26,  2.38it/s, Loss=3.07, Accuracy=0.234]                        \n",
      "Processing Batch 46: 63it [00:27,  2.27it/s, Loss=3.05, Accuracy=0.236]                        \n",
      "Processing Batch 47: 63it [00:27,  2.26it/s, Loss=3.03, Accuracy=0.239]                        \n",
      "Processing Batch 48: 63it [00:27,  2.26it/s, Loss=3.02, Accuracy=0.24]                         \n",
      "Processing Batch 49: 63it [00:28,  2.23it/s, Loss=2.99, Accuracy=0.242]                        \n",
      "Processing Batch 50: 63it [00:27,  2.26it/s, Loss=3, Accuracy=0.243]                           \n",
      "Processing Batch 51: 63it [00:28,  2.21it/s, Loss=3.03, Accuracy=0.236]                        \n",
      "Processing Batch 52: 63it [00:26,  2.39it/s, Loss=3, Accuracy=0.244]                           \n",
      "Processing Batch 53: 63it [00:27,  2.28it/s, Loss=2.99, Accuracy=0.244]                        \n",
      "Processing Batch 54: 63it [00:29,  2.17it/s, Loss=2.97, Accuracy=0.247]                        \n",
      "Processing Batch 55: 63it [00:29,  2.11it/s, Loss=2.97, Accuracy=0.245]                        \n",
      "Processing Batch 56: 63it [00:28,  2.20it/s, Loss=2.97, Accuracy=0.243]                        \n",
      "Processing Batch 57: 63it [01:10,  1.11s/it, Loss=2.96, Accuracy=0.245]                        \n",
      "Processing Batch 58: 63it [03:11,  3.03s/it, Loss=2.96, Accuracy=0.248]                        \n",
      "Processing Batch 59: 63it [03:01,  2.89s/it, Loss=2.94, Accuracy=0.249]                        \n",
      "Processing Batch 60: 63it [02:45,  2.63s/it, Loss=2.96, Accuracy=0.249]                        \n",
      "Processing Batch 61:  10%|▉         | 6/62 [00:18<02:52,  3.08s/it, Loss=2.96, Accuracy=0.245]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(games), game_batch_size):\n\u001b[0;32m    101\u001b[0m     game_batch \u001b[38;5;241m=\u001b[39m [game\u001b[38;5;241m.\u001b[39mpgn \u001b[38;5;28;01mfor\u001b[39;00m game \u001b[38;5;129;01min\u001b[39;00m games[i:i \u001b[38;5;241m+\u001b[39m game_batch_size]]\n\u001b[1;32m--> 102\u001b[0m     loss, accuracy, moves \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_moves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m moves\n\u001b[0;32m    104\u001b[0m     total_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy \u001b[38;5;241m*\u001b[39m moves\n",
      "Cell \u001b[1;32mIn[5], line 71\u001b[0m, in \u001b[0;36mtrain_on_batch\u001b[1;34m(games, model, optimizer, criterion, device, skip_moves)\u001b[0m\n\u001b[0;32m     68\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     69\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, accuracy, total_moves\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def board_to_input(board):\n",
    "    board_planes = np.zeros((8, 8, 12), dtype=np.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    return board_planes\n",
    "\n",
    "#Encode the move\n",
    "def move_to_output(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def calculate_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == target).sum().item()\n",
    "    return correct / target.size(0)\n",
    "\n",
    "#Training step with move skipping and batching\n",
    "def train_on_batch(games, model, optimizer, criterion, device, skip_moves=10):\n",
    "    all_board_inputs = []\n",
    "    all_targets = []\n",
    "    total_moves = 0\n",
    "\n",
    "    for game_str in games:\n",
    "        pgn_io = io.StringIO(game_str)\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        board = game.board()\n",
    "        move_count = 0\n",
    "\n",
    "        for move in game.mainline_moves():\n",
    "            #A static number of moves are skipped to avoid overfitting to the opening book\n",
    "            #More sophisticated methods can be used to skip exact amount of book moves, but it is too inefficient for my machine\n",
    "            if move_count < skip_moves:\n",
    "                board.push(move)\n",
    "                move_count += 1\n",
    "                continue\n",
    "\n",
    "            #Prepare the input and output\n",
    "            board_input = board_to_input(board)\n",
    "            board_input = torch.tensor(board_input, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            actual_output = move_to_output(move)\n",
    "            actual_output = torch.tensor([actual_output], dtype=torch.long).to(device)\n",
    "\n",
    "            all_board_inputs.append(board_input)\n",
    "            all_targets.append(actual_output)\n",
    "            total_moves += 1\n",
    "\n",
    "            #Update the board with the actual move\n",
    "            board.push(move)\n",
    "\n",
    "    if all_board_inputs:\n",
    "        #Stack all inputs and targets\n",
    "        batch_inputs = torch.cat(all_board_inputs, dim=0)\n",
    "        batch_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(output, batch_targets)\n",
    "        accuracy = calculate_accuracy(output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item(), accuracy, total_moves\n",
    "    else:\n",
    "        return 0, 0, 0  #If no valid moves in batch\n",
    "\n",
    "#Training loop\n",
    "batch_size = 1000\n",
    "game_batch_size = 16 \n",
    "offset = 0\n",
    "step = 0\n",
    "j = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ChessNet().to(device)\n",
    "#model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_1.pth')) #Load the model from the previous training session\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while True:\n",
    "    games = session.query(ChessGame).offset(offset).limit(batch_size).all()\n",
    "    if not games:\n",
    "        break\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_moves = 0\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(games) // game_batch_size, desc=f\"Processing Batch {offset // batch_size + 1}\") as pbar:\n",
    "        for i in range(0, len(games), game_batch_size):\n",
    "            game_batch = [game.pgn for game in games[i:i + game_batch_size]]\n",
    "            loss, accuracy, moves = train_on_batch(game_batch, model, optimizer, criterion, device, skip_moves=10)\n",
    "            total_loss += loss * moves\n",
    "            total_accuracy += accuracy * moves\n",
    "            total_moves += moves\n",
    "            pbar.update(1)\n",
    "            if total_moves > 0:\n",
    "                pbar.set_postfix({'Loss': total_loss / total_moves, 'Accuracy': total_accuracy / total_moves})\n",
    "    \n",
    "    j += 1\n",
    "    if j % 10 == 0:\n",
    "        model_save_path = os.path.join('savedModels', f'cnn_transformer_model_epoch_{j}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    offset += batch_size\n",
    "    \n",
    "#Close the session and TensorBoard writer\n",
    "#Still have not tried TensorBoard, might not work\n",
    "session.close()\n",
    "model_save_path = os.path.join('savedModels', f'cnn_transformer_model_final.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_34488\\4067602970.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
      "Training Progress:   0%|          | 0/1000 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 10.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 238\u001b[0m\n\u001b[0;32m    234\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_path)\n\u001b[0;32m    236\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m--> 238\u001b[0m \u001b[43mtrain_self_play_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 207\u001b[0m, in \u001b[0;36mtrain_self_play_batch\u001b[1;34m(model, optimizer, num_episodes, batch_size, accumulation_steps)\u001b[0m\n\u001b[0;32m    204\u001b[0m episode_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(accumulation_steps):\n\u001b[1;32m--> 207\u001b[0m     log_probs_batch, rewards_batch, checkmate_count \u001b[38;5;241m=\u001b[39m \u001b[43mplay_batch_games\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Ensure autocast is used only during forward pass\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Enable mixed precision during policy update\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 66\u001b[0m, in \u001b[0;36mplay_batch_games\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m states \u001b[38;5;241m=\u001b[39m [board_to_input(boards[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m active_indices]\n\u001b[0;32m     63\u001b[0m states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(states)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 66\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     67\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(active_indices):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mChessNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(x)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Transformer encoder\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m#[batch_size, sequence_length, d_model]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    413\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 416\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    419\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:750\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[1;32m--> 750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:765\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 765\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 10.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "###### RL PART ######\n",
    "\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_60.pth'))\n",
    "\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "# Function to select a move given the current board position. Not currently used in the training loop whilst trying to fix some stuff\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0) \n",
    "\n",
    "    \n",
    "    logits = model(state) \n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    # Sample from moves based on the distribution of probabilities.\n",
    "    # In the early stages of training, the bot will explore many moves that it does not particularly prefer, \n",
    "    # but as the training progresses, the bot will start to get better, the distribution of probabilities of moves will more greatly favor the better moves, \n",
    "    # leading to less exploration.\n",
    "    move_idx = m.sample() \n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "# Function to simulate a batch of games of self-play\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = [board_to_input(boards[i]) for i in active_indices]\n",
    "        states = torch.cat(states).to(device)\n",
    "\n",
    "        \n",
    "        logits = model(states) \n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                print(\"All legal probabilities are zero\")\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx) \n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                #Greatly reward the bot for checkmating the opponent\n",
    "                rewards[i].append(5)\n",
    "                break\n",
    "\n",
    "            # If too many moves, break\n",
    "            if len(rewards[i]) > 200:\n",
    "                boards[i].push(chess.Move.null())\n",
    "                # Penalize the bot for taking too many moves\n",
    "                rewards[i][-1] -= 0.5\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i]\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "        \n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01 # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1 \n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:  \n",
    "                rewards[i][-1] += 1  \n",
    "                rewards[i][-2] -= 1  \n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5  \n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5  \n",
    "\n",
    "    del states, logits, probabilities\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return log_probs, rewards, checkmate_count\n",
    "\n",
    "\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "# Function to assign value to pieces TODO: fix right values since these are maybe not good\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 0.1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 0.3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 0.5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 0.9\n",
    "    return 0\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, gamma=0.99):\n",
    "    policy_loss = 0\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns, dtype=torch.float32, requires_grad=False).to(device) # requires_grad=False since having problems with torch.no_grad during self-play. Trying to fix it\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            policy_loss += -log_prob * R\n",
    "\n",
    "    return policy_loss\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=4, accumulation_steps=4):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler for mixed precision\n",
    "    total_checkmates = 0\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        episode_loss = 0\n",
    "\n",
    "        for _ in range(accumulation_steps):\n",
    "            log_probs_batch, rewards_batch, checkmate_count = play_batch_games(model, batch_size)\n",
    "            \n",
    "            # Ensure autocast is used only during forward pass\n",
    "            with autocast(device_type=\"cuda\"):  # Enable mixed precision during policy update\n",
    "                policy_loss = update_policy_batch(log_probs_batch, rewards_batch, optimizer)\n",
    "\n",
    "                # Accumulate the loss\n",
    "                episode_loss += policy_loss / accumulation_steps\n",
    "\n",
    "        # Check that episode_loss requires gradients\n",
    "       # assert episode_loss.requires_grad, \"episode_loss does not require gradients.\"\n",
    "\n",
    "        # Backward pass with scaled gradients after accumulation\n",
    "        scaler.scale(episode_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_checkmates += checkmate_count  #Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates / (episode + 1) * batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=16, accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_53220\\3384448319.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_10.pth'))\n",
      "Training Progress:   0%|          | 0/1000 [04:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 230\u001b[0m\n\u001b[0;32m    227\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[43mtrain_self_play_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 212\u001b[0m, in \u001b[0;36mtrain_self_play_batch\u001b[1;34m(model, optimizer, num_episodes, batch_size, accumulate_grad_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_episodes), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    211\u001b[0m     log_probs_batch, rewards_batch, checkmate_count, move_count \u001b[38;5;241m=\u001b[39m play_batch_games(model, batch_size)\n\u001b[1;32m--> 212\u001b[0m     \u001b[43mupdate_policy_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_probs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     total_checkmates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m checkmate_count  \u001b[38;5;66;03m# Count checkmates as metric for progress in early stages\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[7], line 201\u001b[0m, in \u001b[0;36mupdate_policy_batch\u001b[1;34m(log_probs_batch, rewards_batch, optimizer, move_count)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m log_prob, R \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(log_probs, returns):\n\u001b[0;32m    200\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlog_prob \u001b[38;5;241m*\u001b[39m R\n\u001b[1;32m--> 201\u001b[0m         \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    204\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Chess_GitHub\\ChessBot\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming your ChessNet model is defined elsewhere\n",
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_10.pth'))\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Functions to convert board states and moves\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    return board_input.to(device)\n",
    "\n",
    "def move_to_index(move):\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    return from_square * 64 + to_square\n",
    "\n",
    "def piece_value(piece):\n",
    "    if piece is None:\n",
    "        return 0\n",
    "    elif piece.piece_type == chess.PAWN:\n",
    "        return 1\n",
    "    elif piece.piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        return 3\n",
    "    elif piece.piece_type == chess.ROOK:\n",
    "        return 5\n",
    "    elif piece.piece_type == chess.QUEEN:\n",
    "        return 9\n",
    "    return 0\n",
    "\n",
    "def material_balance(board):\n",
    "    white_material = 0\n",
    "    black_material = 0\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            value = piece_value(piece)\n",
    "            if piece.color == chess.WHITE:\n",
    "                white_material += value\n",
    "            else:\n",
    "                black_material += value\n",
    "\n",
    "    return white_material - black_material  # Positive if white has more material\n",
    "\n",
    "def center_control(board):\n",
    "    central_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "    control_score = 0\n",
    "\n",
    "    for square in central_squares:\n",
    "        attackers = board.attackers(chess.WHITE, square)\n",
    "        defenders = board.attackers(chess.BLACK, square)\n",
    "\n",
    "        if len(attackers) > len(defenders):\n",
    "            control_score += 0.1\n",
    "        elif len(attackers) < len(defenders):\n",
    "            control_score -= 0.1\n",
    "\n",
    "    return control_score\n",
    "\n",
    "def select_move(model, board):\n",
    "    state = board_to_input(board)\n",
    "    state = state.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(state)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "\n",
    "    mask = torch.zeros_like(probabilities)\n",
    "    mask[:, legal_indices] = 1  # Mask out illegal moves\n",
    "\n",
    "    legal_probabilities = probabilities * mask  # Apply the mask\n",
    "    legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=1, keepdim=True)  # Re-normalize\n",
    "\n",
    "    m = Categorical(legal_probabilities)\n",
    "    move_idx = m.sample()\n",
    "\n",
    "    selected_move = legal_moves[move_idx.item()]\n",
    "    return selected_move, m.log_prob(move_idx)\n",
    "\n",
    "def dynamic_gamma(move_count):\n",
    "    if move_count < 20:\n",
    "        return 0.95  # Early game\n",
    "    elif move_count < 40:\n",
    "        return 0.98  # Mid game\n",
    "    else:\n",
    "        return 0.99  # End game\n",
    "\n",
    "def play_batch_games(model, batch_size):\n",
    "    boards = [chess.Board() for _ in range(batch_size)]\n",
    "    log_probs = [[] for _ in range(batch_size)]\n",
    "    rewards = [[] for _ in range(batch_size)]\n",
    "    previous_material_balances = [material_balance(board) for board in boards]\n",
    "    checkmate_count = 0\n",
    "    move_count = 0\n",
    "\n",
    "    while any(not board.is_game_over() for board in boards):\n",
    "        active_indices = [i for i, board in enumerate(boards) if not board.is_game_over()]\n",
    "        states = torch.cat([board_to_input(boards[i]) for i in active_indices])\n",
    "\n",
    "        logits = model(states)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        for idx, i in enumerate(active_indices):\n",
    "            legal_moves = list(boards[i].legal_moves)\n",
    "            if len(legal_moves) == 0:\n",
    "                continue  # Skip if no legal moves are available\n",
    "\n",
    "            legal_indices = [move_to_index(move) for move in legal_moves]\n",
    "            mask = torch.zeros_like(probabilities[idx])\n",
    "            mask[legal_indices] = 1\n",
    "            legal_probabilities = probabilities[idx] * mask\n",
    "\n",
    "            if legal_probabilities.sum() == 0:\n",
    "                legal_probabilities = mask  # fallback to uniform distribution over legal moves\n",
    "\n",
    "            legal_probabilities = legal_probabilities / legal_probabilities.sum(dim=0, keepdim=True)\n",
    "\n",
    "            m = Categorical(legal_probabilities)\n",
    "            move_idx = m.sample()\n",
    "\n",
    "            log_prob = m.log_prob(move_idx)\n",
    "            log_probs[i].append(log_prob)\n",
    "\n",
    "            move_idx_in_legal_moves = legal_indices.index(move_idx.item()) if move_idx.item() in legal_indices else None\n",
    "\n",
    "            if move_idx_in_legal_moves is None:\n",
    "                continue  # Safeguard against out-of-bound indices\n",
    "\n",
    "            selected_move = legal_moves[move_idx_in_legal_moves]\n",
    "            boards[i].push(selected_move)\n",
    "\n",
    "            if boards[i].is_checkmate():\n",
    "                checkmate_count += 1  # Increment checkmate counter\n",
    "                break\n",
    "\n",
    "            current_material_balance = material_balance(boards[i])\n",
    "            current_control_score = center_control(boards[i])\n",
    "            reward = current_material_balance - previous_material_balances[i] + current_control_score\n",
    "\n",
    "            if boards[i].turn == chess.WHITE:  # Bot just played as black\n",
    "                rewards[i].append(-reward)  # Negative reward if bot is black (after white's move)\n",
    "            else:  # Bot just played as white\n",
    "                rewards[i].append(reward)  # Positive reward if bot is white (after black's move)\n",
    "\n",
    "            previous_material_balances[i] = current_material_balance\n",
    "            move_count += 1\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        result = boards[i].result()\n",
    "\n",
    "        for j in range(len(rewards[i])):\n",
    "            rewards[i][j] -= 0.01  # Penalize each move to try make the bot not do many unnecessary moves\n",
    "\n",
    "        if result == '1-0':  # White wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '0-1':  # Black wins\n",
    "            if len(rewards[i]) % 2 == 1:\n",
    "                rewards[i][-1] += 1\n",
    "                rewards[i][-2] -= 1\n",
    "\n",
    "        elif result == '1/2-1/2':  # Draw\n",
    "            rewards[i][-1] += 0.5\n",
    "            if len(rewards[i]) > 1:\n",
    "                rewards[i][-2] += 0.5\n",
    "\n",
    "    return log_probs, rewards, checkmate_count, move_count\n",
    "\n",
    "def update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count):\n",
    "    optimizer.zero_grad()\n",
    "    gamma = dynamic_gamma(move_count)\n",
    "\n",
    "    for log_probs, rewards in zip(log_probs_batch, rewards_batch):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns).to(device)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-5)  # Normalize returns\n",
    "\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            loss = -log_prob * R\n",
    "            scaler.scale(loss).backward(retain_graph=True)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "def train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4):\n",
    "    model.train()\n",
    "    total_checkmates = 0\n",
    "\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Progress\"):\n",
    "        log_probs_batch, rewards_batch, checkmate_count, move_count = play_batch_games(model, batch_size)\n",
    "        update_policy_batch(log_probs_batch, rewards_batch, optimizer, move_count)\n",
    "\n",
    "        total_checkmates += checkmate_count  # Count checkmates as metric for progress in early stages\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = sum(sum(rewards) for rewards in rewards_batch) / batch_size\n",
    "            print(f\"Episode {episode} complete - Average Reward: {avg_reward:.2f}, Checkmates: {total_checkmates/(episode+1)*batch_size:.2f}%\")\n",
    "            total_checkmates = 0\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            model_save_path = os.path.join('savedModels', f'cnn_transformer_model_rl_{episode}.pth')\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Start training\n",
    "train_self_play_batch(model, optimizer, num_episodes=1000, batch_size=8, accumulate_grad_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChessNet()\n",
    "model.load_state_dict(torch.load('savedModels/cnn_transformer_model_epoch_1.pth'))\n",
    "model.eval()\n",
    "\n",
    "board = chess.Board()\n",
    "\n",
    "def board_to_input(board):\n",
    "    board_planes = torch.zeros((8, 8, 12), dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            plane = piece.piece_type - 1\n",
    "            if piece.color == chess.BLACK:\n",
    "                plane += 6\n",
    "            row, col = divmod(square, 8)\n",
    "            board_planes[row, col, plane] = 1\n",
    "    board_input = board_planes.unsqueeze(0).permute(0, 3, 1, 2) \n",
    "    return board_input\n",
    "\n",
    "def predict_move(model, board):\n",
    "    board_input = board_to_input(board)\n",
    "    with torch.no_grad():\n",
    "        output = model(board_input)\n",
    "    \n",
    "    move_scores = output.squeeze().sort(descending=True)\n",
    "    move_indices = move_scores.indices.tolist()\n",
    "    \n",
    "    for move_index in move_indices:\n",
    "        from_square = move_index // 64\n",
    "        to_square = move_index % 64\n",
    "        move = chess.Move(from_square, to_square)\n",
    "        \n",
    "        if move in board.legal_moves:\n",
    "            return move\n",
    "    \n",
    "    # If no valid moves are found (which shouldn't happen), return None\n",
    "    return None\n",
    "\n",
    "\n",
    "while not board.is_game_over():\n",
    "    display(board)  \n",
    "    user_move = input(\"Your move: \")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        move = chess.Move.from_uci(user_move)\n",
    "        if move in board.legal_moves:\n",
    "            board.push(move)\n",
    "        else:\n",
    "            print(\"Invalid move. Try again.\")\n",
    "            continue\n",
    "    except ValueError:\n",
    "        print(\"Invalid format. Use UCI format (e.g., e2e4).\")\n",
    "        continue\n",
    "\n",
    "    if board.is_game_over():\n",
    "        break\n",
    "\n",
    "    #Get the bots move\n",
    "    bot_move = predict_move(model, board)\n",
    "    if bot_move:\n",
    "        board.push(bot_move)\n",
    "        print(f\"Bot's move: {bot_move}\")\n",
    "    else:\n",
    "        print(\"Bot could not find a valid move.\")\n",
    "        break\n",
    "\n",
    "print(\"Game over!\")\n",
    "print(f\"Result: {board.result()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
